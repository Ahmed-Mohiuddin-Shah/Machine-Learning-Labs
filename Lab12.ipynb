{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Ahmed Mohiuddin Shah\n",
    "### CMS ID: 415216\n",
    "### Section: BSCS-12-A\n",
    "### Lab: 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreLab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Virtual Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I am using my own local python notebooks and for that I am using a conda virtual environment.\n",
    "- I have made my conda environment at the start of the semester and I have been using it for all my labs.\n",
    "- It is insde the .conda folder\n",
    "- To activate it in the terminal, I use the `conda activate <absolute path>/.conda` command.\n",
    "\n",
    "![activate-env](screenshots/activate-env.png \"activate-env\")\n",
    "\n",
    "- I use VsCode to run my python notebooks and i select the kernel to use the .conda environment in the .conda folder.\n",
    "\n",
    "![kernel-selection](screenshots/kernel-selection.png \"kernel-selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dvc in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (3.58.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (24.2.0)\n",
      "Requirement already satisfied: celery in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (5.4.0)\n",
      "Requirement already satisfied: colorama>=0.3.9 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (0.4.6)\n",
      "Requirement already satisfied: configobj>=5.0.9 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (5.0.9)\n",
      "Requirement already satisfied: distro>=1.3 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (1.9.0)\n",
      "Requirement already satisfied: dpath<3,>=2.1.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (2.2.0)\n",
      "Requirement already satisfied: dulwich in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (0.22.6)\n",
      "Requirement already satisfied: dvc-data<3.17,>=3.16.2 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (3.16.7)\n",
      "Requirement already satisfied: dvc-http>=2.29.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (2.32.0)\n",
      "Requirement already satisfied: dvc-objects in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (5.1.0)\n",
      "Requirement already satisfied: dvc-render<2,>=1.0.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (1.0.2)\n",
      "Requirement already satisfied: dvc-studio-client<1,>=0.21 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (0.21.0)\n",
      "Requirement already satisfied: dvc-task<1,>=0.3.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (0.40.2)\n",
      "Requirement already satisfied: flatten_dict<1,>=0.4.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (0.4.2)\n",
      "Requirement already satisfied: flufl.lock<9,>=8.1.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (8.1.0)\n",
      "Requirement already satisfied: fsspec>=2024.2.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (2024.10.0)\n",
      "Requirement already satisfied: funcy>=1.14 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (2.0)\n",
      "Requirement already satisfied: grandalf<1,>=0.7 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (0.8)\n",
      "Requirement already satisfied: gto<2,>=1.6.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (1.7.2)\n",
      "Requirement already satisfied: hydra-core>=1.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (1.3.2)\n",
      "Requirement already satisfied: iterative-telemetry>=0.0.7 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (0.0.9)\n",
      "Requirement already satisfied: kombu in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (5.4.2)\n",
      "Requirement already satisfied: networkx>=2.5 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (3.4.2)\n",
      "Requirement already satisfied: omegaconf in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (2.3.0)\n",
      "Requirement already satisfied: packaging>=19 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (24.1)\n",
      "Requirement already satisfied: pathspec>=0.10.3 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (0.12.1)\n",
      "Requirement already satisfied: platformdirs<5,>=3.1.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (3.10.0)\n",
      "Requirement already satisfied: psutil>=5.8 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (5.9.0)\n",
      "Requirement already satisfied: pydot>=1.2.4 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (3.0.3)\n",
      "Requirement already satisfied: pygtrie>=2.3.2 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (2.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.4.7 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (3.1.4)\n",
      "Requirement already satisfied: requests>=2.22 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (2.32.3)\n",
      "Requirement already satisfied: rich>=12 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (13.9.4)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.11 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (0.18.6)\n",
      "Requirement already satisfied: scmrepo<4,>=3.3.8 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (3.3.9)\n",
      "Requirement already satisfied: shortuuid>=0.5 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (1.0.13)\n",
      "Requirement already satisfied: shtab<2,>=1.3.4 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (1.7.1)\n",
      "Requirement already satisfied: tabulate>=0.8.7 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (0.9.0)\n",
      "Requirement already satisfied: tomlkit>=0.11.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (0.13.2)\n",
      "Requirement already satisfied: tqdm<5,>=4.63.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (4.66.5)\n",
      "Requirement already satisfied: voluptuous>=0.11.7 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (0.15.2)\n",
      "Requirement already satisfied: zc.lockfile>=1.2.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc) (3.0.post1)\n",
      "Requirement already satisfied: dictdiffer>=0.8.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc-data<3.17,>=3.16.2->dvc) (0.9.0)\n",
      "Requirement already satisfied: diskcache>=5.2.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc-data<3.17,>=3.16.2->dvc) (5.6.3)\n",
      "Requirement already satisfied: sqltrie<1,>=0.11.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc-data<3.17,>=3.16.2->dvc) (0.11.1)\n",
      "Requirement already satisfied: orjson<4,>=3 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc-data<3.17,>=3.16.2->dvc) (3.10.12)\n",
      "Requirement already satisfied: aiohttp-retry>=2.5.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc-http>=2.29.0->dvc) (2.9.1)\n",
      "Requirement already satisfied: pywin32>=225 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from dvc-task<1,>=0.3.0->dvc) (305.1)\n",
      "Requirement already satisfied: billiard<5.0,>=4.2.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from celery->dvc) (4.2.1)\n",
      "Requirement already satisfied: vine<6.0,>=5.1.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from celery->dvc) (5.1.0)\n",
      "Requirement already satisfied: click<9.0,>=8.1.2 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from celery->dvc) (8.1.7)\n",
      "Requirement already satisfied: click-didyoumean>=0.3.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from celery->dvc) (0.3.1)\n",
      "Requirement already satisfied: click-repl>=0.2.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from celery->dvc) (0.3.0)\n",
      "Requirement already satisfied: click-plugins>=1.1.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from celery->dvc) (1.1.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from celery->dvc) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from celery->dvc) (2.9.0.post0)\n",
      "Requirement already satisfied: six<2.0,>=1.12 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from flatten_dict<1,>=0.4.1->dvc) (1.16.0)\n",
      "Requirement already satisfied: atpublic in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from flufl.lock<9,>=8.1.0->dvc) (5.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from gto<2,>=1.6.0->dvc) (0.4)\n",
      "Requirement already satisfied: pydantic!=2.0.0,<3,>=1.9.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from gto<2,>=1.6.0->dvc) (2.10.3)\n",
      "Requirement already satisfied: semver>=2.13.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from gto<2,>=1.6.0->dvc) (3.0.2)\n",
      "Requirement already satisfied: typer>=0.4.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from gto<2,>=1.6.0->dvc) (0.15.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from hydra-core>=1.1->dvc) (4.9.3)\n",
      "Requirement already satisfied: appdirs in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from iterative-telemetry>=0.0.7->dvc) (1.4.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from iterative-telemetry>=0.0.7->dvc) (3.16.1)\n",
      "Requirement already satisfied: amqp<6.0.0,>=5.1.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from kombu->dvc) (5.3.1)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from omegaconf->dvc) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from requests>=2.22->dvc) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from requests>=2.22->dvc) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from requests>=2.22->dvc) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from requests>=2.22->dvc) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from rich>=12->dvc) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from rich>=12->dvc) (2.15.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from rich>=12->dvc) (4.12.2)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from ruamel.yaml>=0.17.11->dvc) (0.2.12)\n",
      "Requirement already satisfied: gitpython>3 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from scmrepo<4,>=3.3.8->dvc) (3.1.43)\n",
      "Requirement already satisfied: pygit2>=1.14.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from scmrepo<4,>=3.3.8->dvc) (1.16.0)\n",
      "Requirement already satisfied: asyncssh<3,>=2.13.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from scmrepo<4,>=3.3.8->dvc) (2.18.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from zc.lockfile>=1.2.1->dvc) (75.1.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (3.11.10)\n",
      "Requirement already satisfied: cryptography>=39.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from asyncssh<3,>=2.13.1->scmrepo<4,>=3.3.8->dvc) (44.0.0)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.36 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from click-repl>=0.2.0->celery->dvc) (3.0.43)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from gitpython>3->scmrepo<4,>=3.3.8->dvc) (4.0.11)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12->dvc) (0.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.6.0->dvc) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.6.0->dvc) (2.27.1)\n",
      "Requirement already satisfied: cffi>=1.17.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from pygit2>=1.14.0->scmrepo<4,>=3.3.8->dvc) (1.17.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from typer>=0.4.1->gto<2,>=1.6.0->dvc) (1.5.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (1.18.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from cffi>=1.17.0->pygit2>=1.14.0->scmrepo<4,>=3.3.8->dvc) (2.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython>3->scmrepo<4,>=3.3.8->dvc) (5.0.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery->dvc) (0.2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install numpy pandas scikit-learn dvc mlflow\n",
    "%pip install dvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohappyeyeballs==2.4.4\n",
      "aiohttp==3.11.10\n",
      "aiohttp-retry==2.9.1\n",
      "aiosignal==1.3.1\n",
      "alembic==1.14.0\n",
      "amqp==5.3.1\n",
      "annotated-types==0.7.0\n",
      "antlr4-python3-runtime==4.9.3\n",
      "appdirs==1.4.4\n",
      "asttokens @ file:///opt/conda/conda-bld/asttokens_1646925590279/work\n",
      "async-timeout==5.0.1\n",
      "asyncssh==2.18.0\n",
      "atpublic==5.0\n",
      "attrs==24.2.0\n",
      "billiard==4.2.1\n",
      "bleach==6.1.0\n",
      "blinker==1.9.0\n",
      "cachetools==5.5.0\n",
      "celery==5.4.0\n",
      "certifi==2024.8.30\n",
      "cffi==1.17.1\n",
      "charset-normalizer==3.3.2\n",
      "click==8.1.7\n",
      "click-didyoumean==0.3.1\n",
      "click-plugins==1.1.1\n",
      "click-repl==0.3.0\n",
      "cloudpickle==3.1.0\n",
      "colorama @ file:///C:/b/abs_a9ozq0l032/croot/colorama_1672387194846/work\n",
      "comm @ file:///C:/b/abs_67a8058udb/croot/comm_1709322909844/work\n",
      "configobj==5.0.9\n",
      "contourpy==1.3.0\n",
      "cryptography==44.0.0\n",
      "cycler==0.12.1\n",
      "daal==2025.0.0\n",
      "databricks-sdk==0.38.0\n",
      "debugpy @ file:///C:/b/abs_c0y1fjipt2/croot/debugpy_1690906864587/work\n",
      "decorator @ file:///opt/conda/conda-bld/decorator_1643638310831/work\n",
      "Deprecated==1.2.15\n",
      "dictdiffer==0.9.0\n",
      "diskcache==5.6.3\n",
      "distro==1.9.0\n",
      "docker==7.1.0\n",
      "dpath==2.2.0\n",
      "dulwich==0.22.6\n",
      "dvc==3.58.0\n",
      "dvc-data==3.16.7\n",
      "dvc-http==2.32.0\n",
      "dvc-objects==5.1.0\n",
      "dvc-render==1.0.2\n",
      "dvc-studio-client==0.21.0\n",
      "dvc-task==0.40.2\n",
      "entrypoints==0.4\n",
      "exceptiongroup @ file:///C:/b/abs_c5h1o1_b5b/croot/exceptiongroup_1706031441653/work\n",
      "executing @ file:///opt/conda/conda-bld/executing_1646925071911/work\n",
      "filelock==3.16.1\n",
      "Flask==3.1.0\n",
      "flatten-dict==0.4.2\n",
      "flufl.lock==8.1.0\n",
      "fonttools==4.54.0\n",
      "frozenlist==1.5.0\n",
      "fsspec==2024.10.0\n",
      "funcy==2.0\n",
      "gitdb==4.0.11\n",
      "GitPython==3.1.43\n",
      "google-auth==2.36.0\n",
      "grandalf==0.8\n",
      "graphene==3.4.3\n",
      "graphql-core==3.2.5\n",
      "graphql-relay==3.2.0\n",
      "greenlet==3.1.1\n",
      "gto==1.7.2\n",
      "hdbscan==0.8.40\n",
      "hydra-core==1.3.2\n",
      "idna==3.10\n",
      "importlib_metadata==8.5.0\n",
      "ipykernel @ file:///C:/b/abs_c2u94kxcy6/croot/ipykernel_1705933907920/work\n",
      "ipython @ file:///C:/b/abs_53it5seiim/croot/ipython_1726064251844/work\n",
      "iterative-telemetry==0.0.9\n",
      "itsdangerous==2.2.0\n",
      "jedi @ file:///C:/b/abs_1b8kmj7rrm/croot/jedi_1721058359741/work\n",
      "Jinja2==3.1.4\n",
      "joblib==1.4.2\n",
      "jupyter_client @ file:///C:/b/abs_a6h3c8hfdq/croot/jupyter_client_1699455939372/work\n",
      "jupyter_core @ file:///C:/b/abs_beftpbuevw/croot/jupyter_core_1718818307097/work\n",
      "kaggle==1.6.17\n",
      "kagglehub==0.3.4\n",
      "kiwisolver==1.4.7\n",
      "kombu==5.4.2\n",
      "llvmlite==0.43.0\n",
      "Mako==1.3.8\n",
      "Markdown==3.7\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==3.0.2\n",
      "matplotlib==3.9.2\n",
      "matplotlib-inline @ file:///C:/ci/matplotlib-inline_1661934094726/work\n",
      "mdurl==0.1.2\n",
      "mlflow==2.18.0\n",
      "mlflow-skinny==2.18.0\n",
      "mlxtend==0.23.3\n",
      "multidict==6.1.0\n",
      "nest-asyncio @ file:///C:/b/abs_65d6lblmoi/croot/nest-asyncio_1708532721305/work\n",
      "networkx==3.4.2\n",
      "numba==0.60.0\n",
      "numpy==2.0.2\n",
      "omegaconf==2.3.0\n",
      "opencv-python==4.10.0.84\n",
      "opentelemetry-api==1.28.2\n",
      "opentelemetry-sdk==1.28.2\n",
      "opentelemetry-semantic-conventions==0.49b2\n",
      "orjson==3.10.12\n",
      "packaging @ file:///C:/b/abs_c3vlh0z4jw/croot/packaging_1720101866539/work\n",
      "pandas==2.2.3\n",
      "parso @ file:///opt/conda/conda-bld/parso_1641458642106/work\n",
      "pathspec==0.12.1\n",
      "pillow==10.4.0\n",
      "platformdirs @ file:///C:/b/abs_b6z_yqw_ii/croot/platformdirs_1692205479426/work\n",
      "prompt-toolkit @ file:///C:/b/abs_68uwr58ed1/croot/prompt-toolkit_1704404394082/work\n",
      "propcache==0.2.1\n",
      "protobuf==5.29.1\n",
      "psutil @ file:///C:/Windows/Temp/abs_b2c2fd7f-9fd5-4756-95ea-8aed74d0039flsd9qufz/croots/recipe/psutil_1656431277748/work\n",
      "pure-eval @ file:///opt/conda/conda-bld/pure_eval_1646925070566/work\n",
      "pyarrow==18.1.0\n",
      "pyasn1==0.6.1\n",
      "pyasn1_modules==0.4.1\n",
      "pycparser==2.22\n",
      "pydantic==2.10.3\n",
      "pydantic_core==2.27.1\n",
      "pydot==3.0.3\n",
      "pygit2==1.16.0\n",
      "Pygments @ file:///C:/b/abs_fay9dpq4n_/croot/pygments_1684279990574/work\n",
      "pygtrie==2.5.0\n",
      "pyparsing==3.1.4\n",
      "python-dateutil @ file:///C:/b/abs_3au_koqnbs/croot/python-dateutil_1716495777160/work\n",
      "python-slugify==8.0.4\n",
      "pytz==2024.2\n",
      "pywin32==305.1\n",
      "PyYAML==6.0.2\n",
      "pyzmq @ file:///C:/b/abs_89aq69t0up/croot/pyzmq_1705605705281/work\n",
      "requests==2.32.3\n",
      "rich==13.9.4\n",
      "rsa==4.9\n",
      "ruamel.yaml==0.18.6\n",
      "ruamel.yaml.clib==0.2.12\n",
      "scikit-learn==1.5.2\n",
      "scikit-learn-intelex==2025.0.0\n",
      "scipy==1.14.1\n",
      "scmrepo==3.3.9\n",
      "seaborn==0.13.2\n",
      "semver==3.0.2\n",
      "shap==0.46.0\n",
      "shellingham==1.5.4\n",
      "shortuuid==1.0.13\n",
      "shtab==1.7.1\n",
      "six @ file:///tmp/build/80754af9/six_1644875935023/work\n",
      "slicer==0.0.8\n",
      "smmap==5.0.1\n",
      "SQLAlchemy==2.0.36\n",
      "sqlparse==0.5.2\n",
      "sqltrie==0.11.1\n",
      "stack-data @ file:///opt/conda/conda-bld/stack_data_1646927590127/work\n",
      "tabulate==0.9.0\n",
      "tbb==2022.0.0\n",
      "tcmlib==1.2.0\n",
      "text-unidecode==1.3\n",
      "threadpoolctl==3.5.0\n",
      "tomlkit==0.13.2\n",
      "tornado @ file:///C:/b/abs_7bua0304mj/croot/tornado_1718740122405/work\n",
      "tqdm==4.66.5\n",
      "traitlets @ file:///C:/b/abs_bfsnoxl4pq/croot/traitlets_1718227069245/work\n",
      "typer==0.15.1\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2024.2\n",
      "ucimlrepo==0.0.7\n",
      "urllib3==2.2.3\n",
      "vine==5.1.0\n",
      "voluptuous==0.15.2\n",
      "waitress==3.0.2\n",
      "wcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work\n",
      "webencodings==0.5.1\n",
      "Werkzeug==3.1.3\n",
      "wrapt==1.17.0\n",
      "yarl==1.18.3\n",
      "zc.lockfile==3.0.post1\n",
      "zipp==3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am working on windows and I had already installed and setup git on my Laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n",
      "           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n",
      "           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n",
      "           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n",
      "           [--config-env=<name>=<envvar>] <command> [<args>]\n",
      "\n",
      "These are common Git commands used in various situations:\n",
      "\n",
      "start a working area (see also: git help tutorial)\n",
      "   clone     Clone a repository into a new directory\n",
      "   init      Create an empty Git repository or reinitialize an existing one\n",
      "\n",
      "work on the current change (see also: git help everyday)\n",
      "   add       Add file contents to the index\n",
      "   mv        Move or rename a file, a directory, or a symlink\n",
      "   restore   Restore working tree files\n",
      "   rm        Remove files from the working tree and from the index\n",
      "\n",
      "examine the history and state (see also: git help revisions)\n",
      "   bisect    Use binary search to find the commit that introduced a bug\n",
      "   diff      Show changes between commits, commit and working tree, etc\n",
      "   grep      Print lines matching a pattern\n",
      "   log       Show commit logs\n",
      "   show      Show various types of objects\n",
      "   status    Show the working tree status\n",
      "\n",
      "grow, mark and tweak your common history\n",
      "   branch    List, create, or delete branches\n",
      "   commit    Record changes to the repository\n",
      "   merge     Join two or more development histories together\n",
      "   rebase    Reapply commits on top of another base tip\n",
      "   reset     Reset current HEAD to the specified state\n",
      "   switch    Switch branches\n",
      "   tag       Create, list, delete or verify a tag object signed with GPG\n",
      "\n",
      "collaborate (see also: git help workflows)\n",
      "   fetch     Download objects and refs from another repository\n",
      "   pull      Fetch from and integrate with another repository or a local branch\n",
      "   push      Update remote refs along with associated objects\n",
      "\n",
      "'git help -a' and 'git help -g' list available subcommands and some\n",
      "concept guides. See 'git help <command>' or 'git help <concept>'\n",
      "to read about a specific subcommand or concept.\n",
      "See 'git help git' for an overview of the system.\n"
     ]
    }
   ],
   "source": [
    "!git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in C:/Users/Ahmed Mohiuddin Shah/Documents/Machine Learning Labs/.git/\n",
      "[main (root-commit) 860d44f] Initial commit\n",
      " 220 files changed, 142487 insertions(+)\n",
      " create mode 100644 .gitignore\n",
      " create mode 100644 Assignment 1/Ahmed-Mohiuddin-Shah_415216.zip\n",
      " create mode 100644 Assignment 1/Assignment 1.pdf\n",
      " create mode 100644 Assignment 1/code.ipynb\n",
      " create mode 100644 Assignment 1/data_patient_dropout.csv\n",
      " create mode 100644 Assignment 1/updated_data.csv\n",
      " create mode 100644 Assignment 2/AhmedMohiuddinShah_415216.zip\n",
      " create mode 100644 Assignment 2/Assignment 2.pdf\n",
      " create mode 100644 Assignment 2/SVM_Assignment.py\n",
      " create mode 100644 Assignment 2/best_Theme_park_rbf_regression_svm_model.pkl\n",
      " create mode 100644 Assignment 2/best_rock_linear_svm_model.pkl\n",
      " create mode 100644 Assignment 2/best_rock_poly_svm_model.pkl\n",
      " create mode 100644 Assignment 2/best_rock_rbf_svm_model.pkl\n",
      " create mode 100644 Assignment 2/best_theme_park_linear_regression_svm_model.pkl\n",
      " create mode 100644 Assignment 2/code.ipynb\n",
      " create mode 100644 Assignment 2/modified_rock_classification_dataset_test.csv\n",
      " create mode 100644 Assignment 2/modified_rock_classification_dataset_train.csv\n",
      " create mode 100644 Assignment 2/modified_theme_park_visitor_count_dataset_test.csv\n",
      " create mode 100644 Assignment 2/modified_theme_park_visitor_count_dataset_train.csv\n",
      " create mode 100644 Assignment 2/rock_classification_dataset.csv\n",
      " create mode 100644 Assignment 2/theme_park_visitor_count_dataset.csv\n",
      " create mode 100644 Assignment 2/updated_data_classification.csv\n",
      " create mode 100644 Assignment 2/updated_data_regression.csv\n",
      " create mode 100644 Automobile.csv\n",
      " create mode 100644 Lab11.ipynb\n",
      " create mode 100644 Lab12.ipynb\n",
      " create mode 100644 Lab2.ipynb\n",
      " create mode 100644 Lab3.ipynb\n",
      " create mode 100644 Lab4.ipynb\n",
      " create mode 100644 Lab5/Group Lab5 .zip\n",
      " create mode 100644 Lab5/images/R001.png\n",
      " create mode 100644 Lab5/images/R002.png\n",
      " create mode 100644 Lab5/images/R003.png\n",
      " create mode 100644 Lab5/images/R004.png\n",
      " create mode 100644 Lab5/images/R005.png\n",
      " create mode 100644 Lab5/images/R006.png\n",
      " create mode 100644 Lab5/images/R007.png\n",
      " create mode 100644 Lab5/images/R008.png\n",
      " create mode 100644 Lab5/images/R009.png\n",
      " create mode 100644 Lab5/images/R010.png\n",
      " create mode 100644 Lab5/images/R011.png\n",
      " create mode 100644 Lab5/images/R012.png\n",
      " create mode 100644 Lab5/images/R013.png\n",
      " create mode 100644 Lab5/images/R014.png\n",
      " create mode 100644 Lab5/images/R015.png\n",
      " create mode 100644 Lab5/images/R016.png\n",
      " create mode 100644 Lab5/images/R017.png\n",
      " create mode 100644 Lab5/images/R018.png\n",
      " create mode 100644 Lab5/images/R019.png\n",
      " create mode 100644 Lab5/images/R020.png\n",
      " create mode 100644 Lab5/images/R021.png\n",
      " create mode 100644 Lab5/images/R022.png\n",
      " create mode 100644 Lab5/images/R023.png\n",
      " create mode 100644 Lab5/images/R024.png\n",
      " create mode 100644 Lab5/images/R025.png\n",
      " create mode 100644 Lab5/main.ipynb\n",
      " create mode 100644 Lab5/main.py\n",
      " create mode 100644 Lab5/processed/centroid/R001.txt\n",
      " create mode 100644 Lab5/processed/centroid/R002.txt\n",
      " create mode 100644 Lab5/processed/centroid/R003.txt\n",
      " create mode 100644 Lab5/processed/centroid/R004.txt\n",
      " create mode 100644 Lab5/processed/centroid/R005.txt\n",
      " create mode 100644 Lab5/processed/centroid/R006.txt\n",
      " create mode 100644 Lab5/processed/centroid/R007.txt\n",
      " create mode 100644 Lab5/processed/centroid/R008.txt\n",
      " create mode 100644 Lab5/processed/centroid/R009.txt\n",
      " create mode 100644 Lab5/processed/centroid/R010.txt\n",
      " create mode 100644 Lab5/processed/centroid/R011.txt\n",
      " create mode 100644 Lab5/processed/centroid/R012.txt\n",
      " create mode 100644 Lab5/processed/centroid/R013.txt\n",
      " create mode 100644 Lab5/processed/centroid/R014.txt\n",
      " create mode 100644 Lab5/processed/centroid/R015.txt\n",
      " create mode 100644 Lab5/processed/centroid/R016.txt\n",
      " create mode 100644 Lab5/processed/centroid/R017.txt\n",
      " create mode 100644 Lab5/processed/centroid/R018.txt\n",
      " create mode 100644 Lab5/processed/centroid/R019.txt\n",
      " create mode 100644 Lab5/processed/centroid/R020.txt\n",
      " create mode 100644 Lab5/processed/centroid/R021.txt\n",
      " create mode 100644 Lab5/processed/centroid/R022.txt\n",
      " create mode 100644 Lab5/processed/centroid/R023.txt\n",
      " create mode 100644 Lab5/processed/centroid/R024.txt\n",
      " create mode 100644 Lab5/processed/centroid/R025.txt\n",
      " create mode 100644 Lab5/processed/images/R001_processed.png\n",
      " create mode 100644 Lab5/processed/images/R002_processed.png\n",
      " create mode 100644 Lab5/processed/images/R003_processed.png\n",
      " create mode 100644 Lab5/processed/images/R004_processed.png\n",
      " create mode 100644 Lab5/processed/images/R005_processed.png\n",
      " create mode 100644 Lab5/processed/images/R006_processed.png\n",
      " create mode 100644 Lab5/processed/images/R007_processed.png\n",
      " create mode 100644 Lab5/processed/images/R008_processed.png\n",
      " create mode 100644 Lab5/processed/images/R009_processed.png\n",
      " create mode 100644 Lab5/processed/images/R010_processed.png\n",
      " create mode 100644 Lab5/processed/images/R011_processed.png\n",
      " create mode 100644 Lab5/processed/images/R012_processed.png\n",
      " create mode 100644 Lab5/processed/images/R013_processed.png\n",
      " create mode 100644 Lab5/processed/images/R014_processed.png\n",
      " create mode 100644 Lab5/processed/images/R015_processed.png\n",
      " create mode 100644 Lab5/processed/images/R016_processed.png\n",
      " create mode 100644 Lab5/processed/images/R017_processed.png\n",
      " create mode 100644 Lab5/processed/images/R018_processed.png\n",
      " create mode 100644 Lab5/processed/images/R019_processed.png\n",
      " create mode 100644 Lab5/processed/images/R020_processed.png\n",
      " create mode 100644 Lab5/processed/images/R021_processed.png\n",
      " create mode 100644 Lab5/processed/images/R022_processed.png\n",
      " create mode 100644 Lab5/processed/images/R023_processed.png\n",
      " create mode 100644 Lab5/processed/images/R024_processed.png\n",
      " create mode 100644 Lab5/processed/images/R025_processed.png\n",
      " create mode 100644 Lab5/processed/ratio/R001.txt\n",
      " create mode 100644 Lab5/processed/ratio/R002.txt\n",
      " create mode 100644 Lab5/processed/ratio/R003.txt\n",
      " create mode 100644 Lab5/processed/ratio/R004.txt\n",
      " create mode 100644 Lab5/processed/ratio/R005.txt\n",
      " create mode 100644 Lab5/processed/ratio/R006.txt\n",
      " create mode 100644 Lab5/processed/ratio/R007.txt\n",
      " create mode 100644 Lab5/processed/ratio/R008.txt\n",
      " create mode 100644 Lab5/processed/ratio/R009.txt\n",
      " create mode 100644 Lab5/processed/ratio/R010.txt\n",
      " create mode 100644 Lab5/processed/ratio/R011.txt\n",
      " create mode 100644 Lab5/processed/ratio/R012.txt\n",
      " create mode 100644 Lab5/processed/ratio/R013.txt\n",
      " create mode 100644 Lab5/processed/ratio/R014.txt\n",
      " create mode 100644 Lab5/processed/ratio/R015.txt\n",
      " create mode 100644 Lab5/processed/ratio/R016.txt\n",
      " create mode 100644 Lab5/processed/ratio/R017.txt\n",
      " create mode 100644 Lab5/processed/ratio/R018.txt\n",
      " create mode 100644 Lab5/processed/ratio/R019.txt\n",
      " create mode 100644 Lab5/processed/ratio/R020.txt\n",
      " create mode 100644 Lab5/processed/ratio/R021.txt\n",
      " create mode 100644 Lab5/processed/ratio/R022.txt\n",
      " create mode 100644 Lab5/processed/ratio/R023.txt\n",
      " create mode 100644 Lab5/processed/ratio/R024.txt\n",
      " create mode 100644 Lab5/processed/ratio/R025.txt\n",
      " create mode 100644 Lab5/processed/skew/R001.txt\n",
      " create mode 100644 Lab5/processed/skew/R002.txt\n",
      " create mode 100644 Lab5/processed/skew/R003.txt\n",
      " create mode 100644 Lab5/processed/skew/R004.txt\n",
      " create mode 100644 Lab5/processed/skew/R005.txt\n",
      " create mode 100644 Lab5/processed/skew/R006.txt\n",
      " create mode 100644 Lab5/processed/skew/R007.txt\n",
      " create mode 100644 Lab5/processed/skew/R008.txt\n",
      " create mode 100644 Lab5/processed/skew/R009.txt\n",
      " create mode 100644 Lab5/processed/skew/R010.txt\n",
      " create mode 100644 Lab5/processed/skew/R011.txt\n",
      " create mode 100644 Lab5/processed/skew/R012.txt\n",
      " create mode 100644 Lab5/processed/skew/R013.txt\n",
      " create mode 100644 Lab5/processed/skew/R014.txt\n",
      " create mode 100644 Lab5/processed/skew/R015.txt\n",
      " create mode 100644 Lab5/processed/skew/R016.txt\n",
      " create mode 100644 Lab5/processed/skew/R017.txt\n",
      " create mode 100644 Lab5/processed/skew/R018.txt\n",
      " create mode 100644 Lab5/processed/skew/R019.txt\n",
      " create mode 100644 Lab5/processed/skew/R020.txt\n",
      " create mode 100644 Lab5/processed/skew/R021.txt\n",
      " create mode 100644 Lab5/processed/skew/R022.txt\n",
      " create mode 100644 Lab5/processed/skew/R023.txt\n",
      " create mode 100644 Lab5/processed/skew/R024.txt\n",
      " create mode 100644 Lab5/processed/skew/R025.txt\n",
      " create mode 100644 Lab5/processed/slant/R001.txt\n",
      " create mode 100644 Lab5/processed/slant/R002.txt\n",
      " create mode 100644 Lab5/processed/slant/R003.txt\n",
      " create mode 100644 Lab5/processed/slant/R004.txt\n",
      " create mode 100644 Lab5/processed/slant/R005.txt\n",
      " create mode 100644 Lab5/processed/slant/R006.txt\n",
      " create mode 100644 Lab5/processed/slant/R007.txt\n",
      " create mode 100644 Lab5/processed/slant/R008.txt\n",
      " create mode 100644 Lab5/processed/slant/R009.txt\n",
      " create mode 100644 Lab5/processed/slant/R010.txt\n",
      " create mode 100644 Lab5/processed/slant/R011.txt\n",
      " create mode 100644 Lab5/processed/slant/R012.txt\n",
      " create mode 100644 Lab5/processed/slant/R013.txt\n",
      " create mode 100644 Lab5/processed/slant/R014.txt\n",
      " create mode 100644 Lab5/processed/slant/R015.txt\n",
      " create mode 100644 Lab5/processed/slant/R016.txt\n",
      " create mode 100644 Lab5/processed/slant/R017.txt\n",
      " create mode 100644 Lab5/processed/slant/R018.txt\n",
      " create mode 100644 Lab5/processed/slant/R019.txt\n",
      " create mode 100644 Lab5/processed/slant/R020.txt\n",
      " create mode 100644 Lab5/processed/slant/R021.txt\n",
      " create mode 100644 Lab5/processed/slant/R022.txt\n",
      " create mode 100644 Lab5/processed/slant/R023.txt\n",
      " create mode 100644 Lab5/processed/slant/R024.txt\n",
      " create mode 100644 Lab5/processed/slant/R025.txt\n",
      " create mode 100644 Lab5/processed/transitions/R001.txt\n",
      " create mode 100644 Lab5/processed/transitions/R002.txt\n",
      " create mode 100644 Lab5/processed/transitions/R003.txt\n",
      " create mode 100644 Lab5/processed/transitions/R004.txt\n",
      " create mode 100644 Lab5/processed/transitions/R005.txt\n",
      " create mode 100644 Lab5/processed/transitions/R006.txt\n",
      " create mode 100644 Lab5/processed/transitions/R007.txt\n",
      " create mode 100644 Lab5/processed/transitions/R008.txt\n",
      " create mode 100644 Lab5/processed/transitions/R009.txt\n",
      " create mode 100644 Lab5/processed/transitions/R010.txt\n",
      " create mode 100644 Lab5/processed/transitions/R011.txt\n",
      " create mode 100644 Lab5/processed/transitions/R012.txt\n",
      " create mode 100644 Lab5/processed/transitions/R013.txt\n",
      " create mode 100644 Lab5/processed/transitions/R014.txt\n",
      " create mode 100644 Lab5/processed/transitions/R015.txt\n",
      " create mode 100644 Lab5/processed/transitions/R016.txt\n",
      " create mode 100644 Lab5/processed/transitions/R017.txt\n",
      " create mode 100644 Lab5/processed/transitions/R018.txt\n",
      " create mode 100644 Lab5/processed/transitions/R019.txt\n",
      " create mode 100644 Lab5/processed/transitions/R020.txt\n",
      " create mode 100644 Lab5/processed/transitions/R021.txt\n",
      " create mode 100644 Lab5/processed/transitions/R022.txt\n",
      " create mode 100644 Lab5/processed/transitions/R023.txt\n",
      " create mode 100644 Lab5/processed/transitions/R024.txt\n",
      " create mode 100644 Lab5/processed/transitions/R025.txt\n",
      " create mode 100644 Lab6.ipynb\n",
      " create mode 100644 Lab7.ipynb\n",
      " create mode 100644 Lab8.ipynb\n",
      " create mode 100644 Lab9.ipynb\n",
      " create mode 100644 heart.csv\n",
      " create mode 100644 lab10.ipynb\n",
      " create mode 100644 screenshots/kernel-selection.png\n",
      " create mode 100644 student_data.csv\n",
      " create mode 100644 test.zip\n",
      " create mode 100644 titanic.zip\n",
      " create mode 100644 titanic/gender_submission.csv\n",
      " create mode 100644 titanic/test.csv\n",
      " create mode 100644 titanic/train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'Assignment 1/code.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Assignment 2/code.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Lab11.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Lab12.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Lab2.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Lab3.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Lab4.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Lab5/main.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Lab6.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Lab7.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Lab8.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Lab9.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'lab10.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'student_data.csv', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git init . && git add . && git commit -m \"Initial commit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I have added the titanic data set in the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 94C9-F421\n",
      "\n",
      " Directory of c:\\Users\\Ahmed Mohiuddin Shah\\Documents\\Machine Learning Labs\\data\\titanic\n",
      "\n",
      "12/10/2024  03:52 PM    <DIR>          .\n",
      "12/10/2024  03:52 PM    <DIR>          ..\n",
      "10/26/2024  12:05 AM             3,258 gender_submission.csv\n",
      "10/26/2024  12:05 AM            28,629 test.csv\n",
      "10/26/2024  12:05 AM            61,194 train.csv\n",
      "               3 File(s)         93,081 bytes\n",
      "               2 Dir(s)     545,562,624 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir data\\titanic\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/titanic/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                     |\n",
      "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
      "|     Read the analytics documentation (and how to opt-out) here:     |\n",
      "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
      "|                                                                     |\n",
      "+---------------------------------------------------------------------+\n",
      "\n",
      "What's next?\n",
      "------------\n",
      "- Check out the documentation: <https://dvc.org/doc>\n",
      "- Get help and share ideas: <https://dvc.org/chat>\n",
      "- Star us on GitHub: <https://github.com/iterative/dvc>\n"
     ]
    }
   ],
   "source": [
    "!python -m dvc init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   Lab12.ipynb\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git add .dvc .gitignore \n",
    "!git commit -m \"Initialize DVC\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Data to DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\titanic\\train.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m dvc add data/titanic/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 4dcf543] chore: Track train.csv with DVC\n",
      " 1 file changed, 5 insertions(+)\n",
      " create mode 100644 data/titanic/train.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "!git add \"data/titanic/train.csv.dvc\"\n",
    "!git commit -m \"chore: Track train.csv with DVC\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating a Data Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and pipelines are up to date.\n"
     ]
    }
   ],
   "source": [
    "!python -m dvc status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>BRAUND, MR. OWEN HARRIS</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CUMINGS, MRS. JOHN BRADLEY (FLORENCE BRIGGS TH...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>HEIKKINEN, MISS. LAINA</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>FUTRELLE, MRS. JACQUES HEATH (LILY MAY PEEL)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>ALLEN, MR. WILLIAM HENRY</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            BRAUND, MR. OWEN HARRIS    male  22.0      1   \n",
       "1  CUMINGS, MRS. JOHN BRADLEY (FLORENCE BRIGGS TH...  female  38.0      1   \n",
       "2                             HEIKKINEN, MISS. LAINA  female  26.0      0   \n",
       "3       FUTRELLE, MRS. JACQUES HEATH (LILY MAY PEEL)  female  35.0      1   \n",
       "4                           ALLEN, MR. WILLIAM HENRY    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making changes to the data\n",
    "data['Name'] = data['Name'].str.upper()\n",
    "# Saving the changes\n",
    "data.to_csv('data/titanic/train.csv', index=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\titanic\\train.csv.dvc:\n",
      "\tchanged outs:\n",
      "\t\tmodified:           data\\titanic\\train.csv\n"
     ]
    }
   ],
   "source": [
    "!python -m dvc status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\titanic\\train.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 70fe96e] chore: Update train.csv with new data\n",
      " 1 file changed, 2 insertions(+), 2 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!python -m dvc add data/titanic/train.csv \n",
    "!git add data/titanic/train.csv.dvc\n",
    "!git commit -m \"chore: Update train.csv with new data\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Version History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "!python -m dvc list data/titanic/train.csv\n",
    "!python -m dvc list --dvc-only data/titanic/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Building workspace index\n",
      "\n",
      "⠋ Calculating diff\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m dvc diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff --git a/Lab12.ipynb b/Lab12.ipynb\n",
      "index 06ee995..ee671a9 100644\n",
      "--- a/Lab12.ipynb\n",
      "+++ b/Lab12.ipynb\n",
      "@@ -765,7 +765,7 @@\n",
      "   },\n",
      "   {\n",
      "    \"cell_type\": \"code\",\n",
      "-   \"execution_count\": 5,\n",
      "+   \"execution_count\": 13,\n",
      "    \"metadata\": {},\n",
      "    \"outputs\": [\n",
      "     {\n",
      "@@ -906,7 +906,7 @@\n",
      "        \"4      0            373450   8.0500   NaN        S  \"\n",
      "       ]\n",
      "      },\n",
      "-     \"execution_count\": 5,\n",
      "+     \"execution_count\": 13,\n",
      "      \"metadata\": {},\n",
      "      \"output_type\": \"execute_result\"\n",
      "     }\n",
      "@@ -1049,12 +1049,294 @@\n",
      "     \"## Simulating a Data Update\"\n",
      "    ]\n",
      "   },\n",
      "+  {\n",
      "+   \"cell_type\": \"code\",\n",
      "+   \"execution_count\": 12,\n",
      "+   \"metadata\": {},\n",
      "+   \"outputs\": [\n",
      "+    {\n",
      "+     \"name\": \"stdout\",\n",
      "+     \"output_type\": \"stream\",\n",
      "+     \"text\": [\n",
      "+      \"Data and pipelines are up to date.\\n\"\n",
      "+     ]\n",
      "+    }\n",
      "+   ],\n",
      "+   \"source\": [\n",
      "+    \"!python -m dvc status\"\n",
      "+   ]\n",
      "+  },\n",
      "+  {\n",
      "+   \"cell_type\": \"code\",\n",
      "+   \"execution_count\": 16,\n",
      "+   \"metadata\": {},\n",
      "+   \"outputs\": [\n",
      "+    {\n",
      "+     \"data\": {\n",
      "+      \"text/html\": [\n",
      "+       \"<div>\\n\",\n",
      "+       \"<style scoped>\\n\",\n",
      "+       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
      "+       \"        vertical-align: middle;\\n\",\n",
      "+       \"    }\\n\",\n",
      "+       \"\\n\",\n",
      "+       \"    .dataframe tbody tr th {\\n\",\n",
      "+       \"        vertical-align: top;\\n\",\n",
      "+       \"    }\\n\",\n",
      "+       \"\\n\",\n",
      "+       \"    .dataframe thead th {\\n\",\n",
      "+       \"        text-align: right;\\n\",\n",
      "+       \"    }\\n\",\n",
      "+       \"</style>\\n\",\n",
      "+       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
      "+       \"  <thead>\\n\",\n",
      "+       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
      "+       \"      <th></th>\\n\",\n",
      "+       \"      <th>PassengerId</th>\\n\",\n",
      "+       \"      <th>Survived</th>\\n\",\n",
      "+       \"      <th>Pclass</th>\\n\",\n",
      "+       \"      <th>Name</th>\\n\",\n",
      "+       \"      <th>Sex</th>\\n\",\n",
      "+       \"      <th>Age</th>\\n\",\n",
      "+       \"      <th>SibSp</th>\\n\",\n",
      "+       \"      <th>Parch</th>\\n\",\n",
      "+       \"      <th>Ticket</th>\\n\",\n",
      "+       \"      <th>Fare</th>\\n\",\n",
      "+       \"      <th>Cabin</th>\\n\",\n",
      "+       \"      <th>Embarked</th>\\n\",\n",
      "+       \"    </tr>\\n\",\n",
      "+       \"  </thead>\\n\",\n",
      "+       \"  <tbody>\\n\",\n",
      "+       \"    <tr>\\n\",\n",
      "+       \"      <th>0</th>\\n\",\n",
      "+       \"      <td>1</td>\\n\",\n",
      "+       \"      <td>0</td>\\n\",\n",
      "+       \"      <td>3</td>\\n\",\n",
      "+       \"      <td>BRAUND, MR. OWEN HARRIS</td>\\n\",\n",
      "+       \"      <td>male</td>\\n\",\n",
      "+       \"      <td>22.0</td>\\n\",\n",
      "+       \"      <td>1</td>\\n\",\n",
      "+       \"      <td>0</td>\\n\",\n",
      "+       \"      <td>A/5 21171</td>\\n\",\n",
      "+       \"      <td>7.2500</td>\\n\",\n",
      "+       \"      <td>NaN</td>\\n\",\n",
      "+       \"      <td>S</td>\\n\",\n",
      "+       \"    </tr>\\n\",\n",
      "+       \"    <tr>\\n\",\n",
      "+       \"      <th>1</th>\\n\",\n",
      "+       \"      <td>2</td>\\n\",\n",
      "+       \"      <td>1</td>\\n\",\n",
      "+       \"      <td>1</td>\\n\",\n",
      "+       \"      <td>CUMINGS, MRS. JOHN BRADLEY (FLORENCE BRIGGS TH...</td>\\n\",\n",
      "+       \"      <td>female</td>\\n\",\n",
      "+       \"      <td>38.0</td>\\n\",\n",
      "+       \"      <td>1</td>\\n\",\n",
      "+       \"      <td>0</td>\\n\",\n",
      "+       \"      <td>PC 17599</td>\\n\",\n",
      "+       \"      <td>71.2833</td>\\n\",\n",
      "+       \"      <td>C85</td>\\n\",\n",
      "+       \"      <td>C</td>\\n\",\n",
      "+       \"    </tr>\\n\",\n",
      "+       \"    <tr>\\n\",\n",
      "+       \"      <th>2</th>\\n\",\n",
      "+       \"      <td>3</td>\\n\",\n",
      "+       \"      <td>1</td>\\n\",\n",
      "+       \"      <td>3</td>\\n\",\n",
      "+       \"      <td>HEIKKINEN, MISS. LAINA</td>\\n\",\n",
      "+       \"      <td>female</td>\\n\",\n",
      "+       \"      <td>26.0</td>\\n\",\n",
      "+       \"      <td>0</td>\\n\",\n",
      "+       \"      <td>0</td>\\n\",\n",
      "+       \"      <td>STON/O2. 3101282</td>\\n\",\n",
      "+       \"      <td>7.9250</td>\\n\",\n",
      "+       \"      <td>NaN</td>\\n\",\n",
      "+       \"      <td>S</td>\\n\",\n",
      "+       \"    </tr>\\n\",\n",
      "+       \"    <tr>\\n\",\n",
      "+       \"      <th>3</th>\\n\",\n",
      "+       \"      <td>4</td>\\n\",\n",
      "+       \"      <td>1</td>\\n\",\n",
      "+       \"      <td>1</td>\\n\",\n",
      "+       \"      <td>FUTRELLE, MRS. JACQUES HEATH (LILY MAY PEEL)</td>\\n\",\n",
      "+       \"      <td>female</td>\\n\",\n",
      "+       \"      <td>35.0</td>\\n\",\n",
      "+       \"      <td>1</td>\\n\",\n",
      "+       \"      <td>0</td>\\n\",\n",
      "+       \"      <td>113803</td>\\n\",\n",
      "+       \"      <td>53.1000</td>\\n\",\n",
      "+       \"      <td>C123</td>\\n\",\n",
      "+       \"      <td>S</td>\\n\",\n",
      "+       \"    </tr>\\n\",\n",
      "+       \"    <tr>\\n\",\n",
      "+       \"      <th>4</th>\\n\",\n",
      "+       \"      <td>5</td>\\n\",\n",
      "+       \"      <td>0</td>\\n\",\n",
      "+       \"      <td>3</td>\\n\",\n",
      "+       \"      <td>ALLEN, MR. WILLIAM HENRY</td>\\n\",\n",
      "+       \"      <td>male</td>\\n\",\n",
      "+       \"      <td>35.0</td>\\n\",\n",
      "+       \"      <td>0</td>\\n\",\n",
      "+       \"      <td>0</td>\\n\",\n",
      "+       \"      <td>373450</td>\\n\",\n",
      "+       \"      <td>8.0500</td>\\n\",\n",
      "+       \"      <td>NaN</td>\\n\",\n",
      "+       \"      <td>S</td>\\n\",\n",
      "+       \"    </tr>\\n\",\n",
      "+       \"  </tbody>\\n\",\n",
      "+       \"</table>\\n\",\n",
      "+       \"</div>\"\n",
      "+      ],\n",
      "+      \"text/plain\": [\n",
      "+       \"   PassengerId  Survived  Pclass  \\\\\\n\",\n",
      "+       \"0            1         0       3   \\n\",\n",
      "+       \"1            2         1       1   \\n\",\n",
      "+       \"2            3         1       3   \\n\",\n",
      "+       \"3            4         1       1   \\n\",\n",
      "+       \"4            5         0       3   \\n\",\n",
      "+       \"\\n\",\n",
      "+       \"                                                Name     Sex   Age  SibSp  \\\\\\n\",\n",
      "+       \"0                            BRAUND, MR. OWEN HARRIS    male  22.0      1   \\n\",\n",
      "+       \"1  CUMINGS, MRS. JOHN BRADLEY (FLORENCE BRIGGS TH...  female  38.0      1   \\n\",\n",
      "+       \"2                             HEIKKINEN, MISS. LAINA  female  26.0      0   \\n\",\n",
      "+       \"3       FUTRELLE, MRS. JACQUES HEATH (LILY MAY PEEL)  female  35.0      1   \\n\",\n",
      "+       \"4                           ALLEN, MR. WILLIAM HENRY    male  35.0      0   \\n\",\n",
      "+       \"\\n\",\n",
      "+       \"   Parch            Ticket     Fare Cabin Embarked  \\n\",\n",
      "+       \"0      0         A/5 21171   7.2500   NaN        S  \\n\",\n",
      "+       \"1      0          PC 17599  71.2833   C85        C  \\n\",\n",
      "+       \"2      0  STON/O2. 3101282   7.9250   NaN        S  \\n\",\n",
      "+       \"3      0            113803  53.1000  C123        S  \\n\",\n",
      "+       \"4      0            373450   8.0500   NaN        S  \"\n",
      "+      ]\n",
      "+     },\n",
      "+     \"execution_count\": 16,\n",
      "+     \"metadata\": {},\n",
      "+     \"output_type\": \"execute_result\"\n",
      "+    }\n",
      "+   ],\n",
      "+   \"source\": [\n",
      "+    \"# Making changes to the data\\n\",\n",
      "+    \"data['Name'] = data['Name'].str.upper()\\n\",\n",
      "+    \"# Saving the changes\\n\",\n",
      "+    \"data.to_csv('data/titanic/train.csv', index=False)\\n\",\n",
      "+    \"data.head()\"\n",
      "+   ]\n",
      "+  },\n",
      "+  {\n",
      "+   \"cell_type\": \"code\",\n",
      "+   \"execution_count\": 17,\n",
      "+   \"metadata\": {},\n",
      "+   \"outputs\": [\n",
      "+    {\n",
      "+     \"name\": \"stdout\",\n",
      "+     \"output_type\": \"stream\",\n",
      "+     \"text\": [\n",
      "+      \"data\\\\titanic\\\\train.csv.dvc:\\n\",\n",
      "+      \"\\tchanged outs:\\n\",\n",
      "+      \"\\t\\tmodified:           data\\\\titanic\\\\train.csv\\n\"\n",
      "+     ]\n",
      "+    }\n",
      "+   ],\n",
      "+   \"source\": [\n",
      "+    \"!python -m dvc status\"\n",
      "+   ]\n",
      "+  },\n",
      "+  {\n",
      "+   \"cell_type\": \"code\",\n",
      "+   \"execution_count\": 21,\n",
      "+   \"metadata\": {},\n",
      "+   \"outputs\": [\n",
      "+    {\n",
      "+     \"name\": \"stdout\",\n",
      "+     \"output_type\": \"stream\",\n",
      "+     \"text\": [\n",
      "+      \"\\n\",\n",
      "+      \"To track the changes with git, run:\\n\",\n",
      "+      \"\\n\",\n",
      "+      \"\\tgit add 'data\\\\titanic\\\\train.csv.dvc'\\n\",\n",
      "+      \"\\n\",\n",
      "+      \"To enable auto staging, run:\\n\",\n",
      "+      \"\\n\",\n",
      "+      \"\\tdvc config core.autostage true\\n\"\n",
      "+     ]\n",
      "+    },\n",
      "+    {\n",
      "+     \"name\": \"stderr\",\n",
      "+     \"output_type\": \"stream\",\n",
      "+     \"text\": [\n",
      "+      \"⠋ Checking graph\\n\",\n",
      "+      \"\\n\"\n",
      "+     ]\n",
      "+    },\n",
      "+    {\n",
      "+     \"name\": \"stdout\",\n",
      "+     \"output_type\": \"stream\",\n",
      "+     \"text\": [\n",
      "+      \"[main 70fe96e] chore: Update train.csv with new data\\n\",\n",
      "+      \" 1 file changed, 2 insertions(+), 2 deletions(-)\\n\"\n",
      "+     ]\n",
      "+    }\n",
      "+   ],\n",
      "+   \"source\": [\n",
      "+    \"!python -m dvc add data/titanic/train.csv \\n\",\n",
      "+    \"!git add data/titanic/train.csv.dvc\\n\",\n",
      "+    \"!git commit -m \\\"chore: Update train.csv with new data\\\" \"\n",
      "+   ]\n",
      "+  },\n",
      "+  {\n",
      "+   \"cell_type\": \"markdown\",\n",
      "+   \"metadata\": {},\n",
      "+   \"source\": [\n",
      "+    \"## Viewing Version History \"\n",
      "+   ]\n",
      "+  },\n",
      "+  {\n",
      "+   \"cell_type\": \"code\",\n",
      "+   \"execution_count\": 34,\n",
      "+   \"metadata\": {},\n",
      "+   \"outputs\": [\n",
      "+    {\n",
      "+     \"name\": \"stdout\",\n",
      "+     \"output_type\": \"stream\",\n",
      "+     \"text\": [\n",
      "+      \".\\n\",\n",
      "+      \".\\n\"\n",
      "+     ]\n",
      "+    }\n",
      "+   ],\n",
      "+   \"source\": [\n",
      "+    \"!python -m dvc list data/titanic/train.csv\\n\",\n",
      "+    \"!python -m dvc list --dvc-only data/titanic/train.csv\"\n",
      "+   ]\n",
      "+  },\n",
      "+  {\n",
      "+   \"cell_type\": \"code\",\n",
      "+   \"execution_count\": 42,\n",
      "+   \"metadata\": {},\n",
      "+   \"outputs\": [\n",
      "+    {\n",
      "+     \"name\": \"stderr\",\n",
      "+     \"output_type\": \"stream\",\n",
      "+     \"text\": [\n",
      "+      \"⠋ Building workspace index\\n\",\n",
      "+      \"\\n\",\n",
      "+      \"⠋ Calculating diff\\n\",\n",
      "+      \"\\n\"\n",
      "+     ]\n",
      "+    }\n",
      "+   ],\n",
      "+   \"source\": [\n",
      "+    \"!python -m dvc diff\\n\"\n",
      "+   ]\n",
      "+  },\n",
      "   {\n",
      "    \"cell_type\": \"code\",\n",
      "    \"execution_count\": null,\n",
      "    \"metadata\": {},\n",
      "    \"outputs\": [],\n",
      "-   \"source\": []\n",
      "+   \"source\": [\n",
      "+    \"!git diff\"\n",
      "+   ]\n",
      "   }\n",
      "  ],\n",
      "  \"metadata\": {\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'Lab12.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: switching to '76af4951148c79087f059d9390c867f1f99f5c5b'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at 76af495 chore: update ipynb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\tLab12.ipynb\n",
      "M       data\\titanic\\train.csv\n"
     ]
    }
   ],
   "source": [
    "!git checkout 76af4951148c79087f059d9390c867f1f99f5c5b\n",
    "!python -m dvc checkout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M       data\\titanic\\train.csv\n"
     ]
    }
   ],
   "source": [
    "!python -m dvc checkout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Tracking with MLflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: mlflow-skinny==2.18.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (2.18.0)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (1.14.0)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<3 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (2.0.2)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<19,>=4.0.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (18.1.0)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (1.5.2)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (2.0.36)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: waitress<4 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.0)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (0.38.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
      "Requirement already satisfied: packaging<25 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (24.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (5.29.1)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (0.5.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (305.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from graphene<4->mlflow) (3.2.5)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from matplotlib<4->mlflow) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from matplotlib<4->mlflow) (4.54.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from matplotlib<4->mlflow) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from matplotlib<4->mlflow) (3.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==2.18.0->mlflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (2.36.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.2.15)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (0.49b2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (2024.8.30)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.17.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\ahmed mohiuddin shah\\documents\\machine learning labs\\.conda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Server in Terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mlfow-ui](screenshots/mlflow-ui.png \"mlflow-ui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python -m mlflow ui "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ui-mlfow](screenshots/ui-mlflow.png \"ui-mlflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Logging an Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(100, 1) * 10  # Random data\n",
    "y = 2.5 * X.flatten() + np.random.randn(100) * 2  # Linear relationship with noise\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and track the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ran-model-mlflow](screenshots/ran-model-mlflow.png \"ran-model-mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed Mohiuddin Shah\\Documents\\Machine Learning Labs\\.conda\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "2024/12/14 18:17:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run bright-perch-465 at: http://localhost:5000/#/experiments/0/runs/0b247eed85954f0580b7f823ad6c0b90\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(): \n",
    "    # Define and train the model \n",
    "    model = LinearRegression() \n",
    "    model.fit(X_train, y_train) \n",
    "    # Log parameters \n",
    "    mlflow.log_param(\"fit_intercept\", model.fit_intercept) \n",
    "    # Predict and log metrics \n",
    "    y_pred = model.predict(X_test) \n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False) \n",
    "    mlflow.log_metric(\"rmse\", rmse) \n",
    "    # Log the model \n",
    "    mlflow.sklearn.log_model(model, \"linear_model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed Mohiuddin Shah\\Documents\\Machine Learning Labs\\.conda\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "2024/12/14 18:20:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run useful-midge-666 at: http://localhost:5000/#/experiments/0/runs/4bbf64c775a54695a912094c526ac429\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(): \n",
    "    model = LinearRegression(fit_intercept=False) \n",
    "    model.fit(X_train, y_train) \n",
    "    y_pred = model.predict(X_test) \n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False) \n",
    "    mlflow.log_param(\"fit_intercept\", model.fit_intercept) \n",
    "    mlflow.log_metric(\"rmse\", rmse) \n",
    "    mlflow.sklearn.log_model(model, \"linear_model_no_intercept\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![metrics-mlflow](screenshots/metrics-mlflow.png \"mlflow-ui\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branching for Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some test changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git branch experiment-feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git checkout experiment-feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![metrics-mlflow](screenshots/branch.png \"mlflow-ui\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Branch back to main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git checkout main\n",
    "!git merge experiment-feature\n",
    "!git branch -d experiment-feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![metrics-mlflow](screenshots/merge.png \"mlflow-ui\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "import dvc.api\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Branch for Lab12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I have created new branch to track changes.\n",
    "\n",
    "![lab12-branch](screenshots/lab12-branch.png \"lab12-branch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git checkout -b lab12-mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset is not downloading through `fetch_ucirepo` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatasetNotFoundError",
     "evalue": "\"UJIIndoorLoc\" dataset (id=310) exists in the repository, but is not available for import. Please select a dataset from this list: https://archive.ics.uci.edu/datasets?skip=0&take=10&sort=desc&orderBy=NumHits&search=&Python=true",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ujiindoor \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_ucirepo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m310\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ahmed Mohiuddin Shah\\Documents\\Machine Learning Labs\\.conda\\lib\\site-packages\\ucimlrepo\\fetch.py:91\u001b[0m, in \u001b[0;36mfetch_ucirepo\u001b[1;34m(name, id)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# no data URL means that the dataset cannot be imported into Python\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# i.e. it does not yet have a standardized CSV file for pandas to parse\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_url:\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dataset (id=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) exists in the repository, but is not available for import. Please select a dataset from this list: https://archive.ics.uci.edu/datasets?skip=0&take=10&sort=desc&orderBy=NumHits&search=&Python=true\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, \u001b[38;5;28mid\u001b[39m))\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# parse into dataframe using pandas\u001b[39;00m\n\u001b[0;32m     95\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mDatasetNotFoundError\u001b[0m: \"UJIIndoorLoc\" dataset (id=310) exists in the repository, but is not available for import. Please select a dataset from this list: https://archive.ics.uci.edu/datasets?skip=0&take=10&sort=desc&orderBy=NumHits&search=&Python=true"
     ]
    }
   ],
   "source": [
    "# ujiindoor = fetch_ucirepo(id=310)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/ujiindoorloc/trainingData.csv')\n",
    "test_data = pd.read_csv('data/ujiindoorloc/validationData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>WAP010</th>\n",
       "      <th>...</th>\n",
       "      <th>WAP520</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FLOOR</th>\n",
       "      <th>BUILDINGID</th>\n",
       "      <th>SPACEID</th>\n",
       "      <th>RELATIVEPOSITION</th>\n",
       "      <th>USERID</th>\n",
       "      <th>PHONEID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7541.2643</td>\n",
       "      <td>4.864921e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7536.6212</td>\n",
       "      <td>4.864934e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-97</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7519.1524</td>\n",
       "      <td>4.864950e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371714095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7524.5704</td>\n",
       "      <td>4.864934e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7632.1436</td>\n",
       "      <td>4.864982e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>1369909710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
       "0     100     100     100     100     100     100     100     100     100   \n",
       "1     100     100     100     100     100     100     100     100     100   \n",
       "2     100     100     100     100     100     100     100     -97     100   \n",
       "3     100     100     100     100     100     100     100     100     100   \n",
       "4     100     100     100     100     100     100     100     100     100   \n",
       "\n",
       "   WAP010  ...  WAP520  LONGITUDE      LATITUDE  FLOOR  BUILDINGID  SPACEID  \\\n",
       "0     100  ...     100 -7541.2643  4.864921e+06      2           1      106   \n",
       "1     100  ...     100 -7536.6212  4.864934e+06      2           1      106   \n",
       "2     100  ...     100 -7519.1524  4.864950e+06      2           1      103   \n",
       "3     100  ...     100 -7524.5704  4.864934e+06      2           1      102   \n",
       "4     100  ...     100 -7632.1436  4.864982e+06      0           0      122   \n",
       "\n",
       "   RELATIVEPOSITION  USERID  PHONEID   TIMESTAMP  \n",
       "0                 2       2       23  1371713733  \n",
       "1                 2       2       23  1371713691  \n",
       "2                 2       2       23  1371714095  \n",
       "3                 2       2       23  1371713807  \n",
       "4                 2      11       13  1369909710  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>WAP010</th>\n",
       "      <th>...</th>\n",
       "      <th>WAP520</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FLOOR</th>\n",
       "      <th>BUILDINGID</th>\n",
       "      <th>SPACEID</th>\n",
       "      <th>RELATIVEPOSITION</th>\n",
       "      <th>USERID</th>\n",
       "      <th>PHONEID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.0</td>\n",
       "      <td>19937.0</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19937.0</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>1.993700e+04</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>1.993700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>99.823644</td>\n",
       "      <td>99.820936</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.613733</td>\n",
       "      <td>97.130461</td>\n",
       "      <td>94.733661</td>\n",
       "      <td>93.820234</td>\n",
       "      <td>94.693936</td>\n",
       "      <td>99.163766</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-7464.275947</td>\n",
       "      <td>4.864871e+06</td>\n",
       "      <td>1.674575</td>\n",
       "      <td>1.212820</td>\n",
       "      <td>148.429954</td>\n",
       "      <td>1.833024</td>\n",
       "      <td>9.068014</td>\n",
       "      <td>13.021869</td>\n",
       "      <td>1.371421e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.866842</td>\n",
       "      <td>5.798156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.615657</td>\n",
       "      <td>22.931890</td>\n",
       "      <td>30.541335</td>\n",
       "      <td>33.010404</td>\n",
       "      <td>30.305084</td>\n",
       "      <td>12.634045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.402010</td>\n",
       "      <td>6.693318e+01</td>\n",
       "      <td>1.223078</td>\n",
       "      <td>0.833139</td>\n",
       "      <td>58.342106</td>\n",
       "      <td>0.372964</td>\n",
       "      <td>4.988720</td>\n",
       "      <td>5.362410</td>\n",
       "      <td>5.572054e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-97.000000</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-97.000000</td>\n",
       "      <td>-98.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-98.000000</td>\n",
       "      <td>-98.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-7691.338400</td>\n",
       "      <td>4.864746e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.369909e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-7594.737000</td>\n",
       "      <td>4.864821e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.371056e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-7423.060900</td>\n",
       "      <td>4.864852e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.371716e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-7359.193000</td>\n",
       "      <td>4.864930e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.371721e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-7300.818990</td>\n",
       "      <td>4.865017e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.371738e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             WAP001        WAP002   WAP003   WAP004        WAP005  \\\n",
       "count  19937.000000  19937.000000  19937.0  19937.0  19937.000000   \n",
       "mean      99.823644     99.820936    100.0    100.0     99.613733   \n",
       "std        5.866842      5.798156      0.0      0.0      8.615657   \n",
       "min      -97.000000    -90.000000    100.0    100.0    -97.000000   \n",
       "25%      100.000000    100.000000    100.0    100.0    100.000000   \n",
       "50%      100.000000    100.000000    100.0    100.0    100.000000   \n",
       "75%      100.000000    100.000000    100.0    100.0    100.000000   \n",
       "max      100.000000    100.000000    100.0    100.0    100.000000   \n",
       "\n",
       "             WAP006        WAP007        WAP008        WAP009        WAP010  \\\n",
       "count  19937.000000  19937.000000  19937.000000  19937.000000  19937.000000   \n",
       "mean      97.130461     94.733661     93.820234     94.693936     99.163766   \n",
       "std       22.931890     30.541335     33.010404     30.305084     12.634045   \n",
       "min      -98.000000    -99.000000    -98.000000    -98.000000    -99.000000   \n",
       "25%      100.000000    100.000000    100.000000    100.000000    100.000000   \n",
       "50%      100.000000    100.000000    100.000000    100.000000    100.000000   \n",
       "75%      100.000000    100.000000    100.000000    100.000000    100.000000   \n",
       "max      100.000000    100.000000    100.000000    100.000000    100.000000   \n",
       "\n",
       "       ...   WAP520     LONGITUDE      LATITUDE         FLOOR    BUILDINGID  \\\n",
       "count  ...  19937.0  19937.000000  1.993700e+04  19937.000000  19937.000000   \n",
       "mean   ...    100.0  -7464.275947  4.864871e+06      1.674575      1.212820   \n",
       "std    ...      0.0    123.402010  6.693318e+01      1.223078      0.833139   \n",
       "min    ...    100.0  -7691.338400  4.864746e+06      0.000000      0.000000   \n",
       "25%    ...    100.0  -7594.737000  4.864821e+06      1.000000      0.000000   \n",
       "50%    ...    100.0  -7423.060900  4.864852e+06      2.000000      1.000000   \n",
       "75%    ...    100.0  -7359.193000  4.864930e+06      3.000000      2.000000   \n",
       "max    ...    100.0  -7300.818990  4.865017e+06      4.000000      2.000000   \n",
       "\n",
       "            SPACEID  RELATIVEPOSITION        USERID       PHONEID  \\\n",
       "count  19937.000000      19937.000000  19937.000000  19937.000000   \n",
       "mean     148.429954          1.833024      9.068014     13.021869   \n",
       "std       58.342106          0.372964      4.988720      5.362410   \n",
       "min        1.000000          1.000000      1.000000      1.000000   \n",
       "25%      110.000000          2.000000      5.000000      8.000000   \n",
       "50%      129.000000          2.000000     11.000000     13.000000   \n",
       "75%      207.000000          2.000000     13.000000     14.000000   \n",
       "max      254.000000          2.000000     18.000000     24.000000   \n",
       "\n",
       "          TIMESTAMP  \n",
       "count  1.993700e+04  \n",
       "mean   1.371421e+09  \n",
       "std    5.572054e+05  \n",
       "min    1.369909e+09  \n",
       "25%    1.371056e+09  \n",
       "50%    1.371716e+09  \n",
       "75%    1.371721e+09  \n",
       "max    1.371738e+09  \n",
       "\n",
       "[8 rows x 529 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Data to DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\ujiindoorloc\\trainingData.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\ujiindoorloc\\validationData.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m dvc add data/ujiindoorloc/trainingData.csv\n",
    "!python -m dvc add data/ujiindoorloc/validationData.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lab12-mlflow 599a7c3] chore: Track UJIIndoorLoc data with DVC\n",
      " 2 files changed, 10 insertions(+)\n",
      " create mode 100644 data/ujiindoorloc/trainingData.csv.dvc\n",
      " create mode 100644 data/ujiindoorloc/validationData.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "!git add data/ujiindoorloc/trainingData.csv.dvc data/ujiindoorloc/validationData.csv.dvc\n",
    "!git commit -m \"chore: Track UJIIndoorLoc data with DVC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and pipelines are up to date.\n"
     ]
    }
   ],
   "source": [
    "# check the status of the DVC pipeline\n",
    "!python -m dvc status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAP001              0\n",
      "WAP002              0\n",
      "WAP003              0\n",
      "WAP004              0\n",
      "WAP005              0\n",
      "                   ..\n",
      "SPACEID             0\n",
      "RELATIVEPOSITION    0\n",
      "USERID              0\n",
      "PHONEID             0\n",
      "TIMESTAMP           0\n",
      "Length: 529, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WAP001              0\n",
       "WAP002              0\n",
       "WAP003              0\n",
       "WAP004              0\n",
       "WAP005              0\n",
       "                   ..\n",
       "SPACEID             0\n",
       "RELATIVEPOSITION    0\n",
       "USERID              0\n",
       "PHONEID             0\n",
       "TIMESTAMP           0\n",
       "Length: 529, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data for missing values\n",
    "for i in train_data.isnull().sum():\n",
    "    if i > 0:\n",
    "        print('Missing values in train_data')\n",
    "        break\n",
    "\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "for i in test_data.isnull().sum():\n",
    "    if i > 0:\n",
    "        print(\"Missing values in train_data\")\n",
    "        break\n",
    "\n",
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check data for duplicates\n",
    "print(train_data.duplicated().sum())\n",
    "print(test_data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "train_data.drop_duplicates(inplace=True)\n",
    "# test_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the changes\n",
    "train_data.to_csv('data/ujiindoorloc/trainingData.csv', index=False)\n",
    "test_data.to_csv('data/ujiindoorloc/validationData.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\ujiindoorloc\\trainingData.csv.dvc:\n",
      "\tchanged outs:\n",
      "\t\tmodified:           data\\ujiindoorloc\\trainingData.csv\n",
      "data\\ujiindoorloc\\validationData.csv.dvc:\n",
      "\tchanged outs:\n",
      "\t\tmodified:           data\\ujiindoorloc\\validationData.csv\n"
     ]
    }
   ],
   "source": [
    "# check the status of the DVC pipeline\n",
    "!python -m dvc status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\ujiindoorloc\\validationData.csv.dvc' 'data\\ujiindoorloc\\trainingData.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add changes to dvc\n",
    "!python -m dvc add data/ujiindoorloc/trainingData.csv data/ujiindoorloc/validationData.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and pipelines are up to date.\n"
     ]
    }
   ],
   "source": [
    "!python -m dvc status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/15 01:15:20 INFO mlflow.tracking.fluent: Experiment with name 'UJIIndoorLoc' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/297993574587620654', creation_time=1734207320289, experiment_id='297993574587620654', last_update_time=1734207320289, lifecycle_stage='active', name='UJIIndoorLoc', tags={}>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"UJIIndoorLoc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Predicting the BuildingID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split to x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['BUILDINGID'])\n",
    "y_train = train_data['BUILDINGID']\n",
    "\n",
    "X_test = test_data.drop(columns=['BUILDINGID'])\n",
    "y_test = test_data['BUILDINGID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1st Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/15 01:15:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run RandomForest_BuildingID_default at: http://localhost:5000/#/experiments/297993574587620654/runs/2ed5dbe47d0642cf86e10e2d4a6703c8\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/297993574587620654\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"RandomForest_BuildingID_default\"):\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.sklearn.log_model(model, \"random_forest\")\n",
    "    confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    mlflow.log_param(\"confusion_matrix\", confusion_matrix.to_json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2nd Run after hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/15 01:17:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run RandomForest_BuildingID_tuned_hyprparameters at: http://localhost:5000/#/experiments/297993574587620654/runs/335828d7dc984b3dbce6960835121f34\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/297993574587620654\n",
      "Data and pipelines are up to date.\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 150],\n",
    "    \"max_depth\": [10, 20, 30],\n",
    "    \"min_samples_split\": [2, 4, 6],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name=\"RandomForest_BuildingID_tuned_hyprparameters\"):\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    model = grid_search.best_estimator_\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_tuned\")\n",
    "    mlflow.log_param(\"best_params\", grid_search.best_params_)\n",
    "    confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    mlflow.log_param(\"confusion_matrix\", confusion_matrix.to_json())\n",
    "\n",
    "# check the status of the DVC pipeline\n",
    "!python -m dvc status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Predicting the Floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1st Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=[\"FLOOR\"])\n",
    "y_train = train_data[\"FLOOR\"]\n",
    "\n",
    "X_test = test_data.drop(columns=[\"FLOOR\"])\n",
    "y_test = test_data[\"FLOOR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/15 01:17:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run RandomForest_Floor_default at: http://localhost:5000/#/experiments/297993574587620654/runs/c2e37d6515c74f67b4db94469791462c\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/297993574587620654\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"RandomForest_Floor_default\"):\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.sklearn.log_model(model, \"random_forest\")\n",
    "    confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    mlflow.log_param(\"confusion_matrix\", confusion_matrix.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/15 01:21:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run RandomForest_Floor_tuned_hyprparameters at: http://localhost:5000/#/experiments/297993574587620654/runs/3ddfe607aaf749619067715da12e85a4\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/297993574587620654\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"RandomForest_Floor_tuned_hyprparameters\"):\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    model = grid_search.best_estimator_\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_tuned\")\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    mlflow.log_param(\"confusion_matrix\", confusion_matrix.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train data into two\n",
    "train_data1, train_data2 = train_data, train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/343853780785666831', creation_time=1734207890504, experiment_id='343853780785666831', last_update_time=1734207890504, lifecycle_stage='active', name='data_drift_experiment', tags={}>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"data_drift_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce data drift to 10% of second dataset\n",
    "data_drifted = train_data2.copy()\n",
    "\n",
    "for col in data_drifted.columns:\n",
    "    if col in [\"FLOOR\", \"BUILDINGID\"]:\n",
    "        continue\n",
    "    data_drifted[col] = data_drifted[col] + np.random.normal(0, 1, len(data_drifted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate KL divergence\n",
    "def kl_divergence(p, q):\n",
    "    \"\"\"Calculate KL divergences between two distributions.\"\"\"\n",
    "    p = np.array(p)\n",
    "    q = np.array(q)\n",
    "    return entropy(p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run DataDrift at: http://localhost:5000/#/experiments/343853780785666831/runs/4ec358c07d424fc982548abe43853b55\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/343853780785666831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'WAP001': np.float64(3.40124621630205),\n",
       " 'WAP002': np.float64(3.3101343379742403),\n",
       " 'WAP003': np.float64(3.407955920515467),\n",
       " 'WAP004': np.float64(3.4365292929596056),\n",
       " 'WAP005': np.float64(3.3563601725868257),\n",
       " 'WAP006': np.float64(3.908883993935609),\n",
       " 'WAP007': np.float64(2.964875839917425),\n",
       " 'WAP008': np.float64(3.0029808675274263),\n",
       " 'WAP009': np.float64(inf),\n",
       " 'WAP010': np.float64(3.7542591278293287),\n",
       " 'WAP011': np.float64(inf),\n",
       " 'WAP012': np.float64(inf),\n",
       " 'WAP013': np.float64(3.3676796000205584),\n",
       " 'WAP014': np.float64(3.7489634632243987),\n",
       " 'WAP015': np.float64(3.5042786328136755),\n",
       " 'WAP016': np.float64(3.6243842129873522),\n",
       " 'WAP017': np.float64(5.987449915411312),\n",
       " 'WAP018': np.float64(3.6189889230034833),\n",
       " 'WAP019': np.float64(inf),\n",
       " 'WAP020': np.float64(5.026628162608788),\n",
       " 'WAP021': np.float64(4.4961726309090215),\n",
       " 'WAP022': np.float64(3.1458372624219066),\n",
       " 'WAP023': np.float64(inf),\n",
       " 'WAP024': np.float64(3.4791504679930543),\n",
       " 'WAP025': np.float64(inf),\n",
       " 'WAP026': np.float64(inf),\n",
       " 'WAP027': np.float64(inf),\n",
       " 'WAP028': np.float64(3.929134586924742),\n",
       " 'WAP029': np.float64(3.2791110875456733),\n",
       " 'WAP030': np.float64(inf),\n",
       " 'WAP031': np.float64(inf),\n",
       " 'WAP032': np.float64(2.672739726723015),\n",
       " 'WAP033': np.float64(3.099569464928413),\n",
       " 'WAP034': np.float64(3.381593456013842),\n",
       " 'WAP035': np.float64(inf),\n",
       " 'WAP036': np.float64(2.65420430153059),\n",
       " 'WAP037': np.float64(4.355288083407998),\n",
       " 'WAP038': np.float64(5.275642913256484),\n",
       " 'WAP039': np.float64(3.81627189041555),\n",
       " 'WAP040': np.float64(inf),\n",
       " 'WAP041': np.float64(inf),\n",
       " 'WAP042': np.float64(3.058958266655999),\n",
       " 'WAP043': np.float64(2.856076918432822),\n",
       " 'WAP044': np.float64(3.6804914808361353),\n",
       " 'WAP045': np.float64(3.7889385545385363),\n",
       " 'WAP046': np.float64(2.898952493654233),\n",
       " 'WAP047': np.float64(inf),\n",
       " 'WAP048': np.float64(2.8217550763096466),\n",
       " 'WAP049': np.float64(4.522539895779051),\n",
       " 'WAP050': np.float64(3.6126712217570236),\n",
       " 'WAP051': np.float64(3.395445192861603),\n",
       " 'WAP052': np.float64(inf),\n",
       " 'WAP053': np.float64(2.942611330012131),\n",
       " 'WAP054': np.float64(2.620916166485583),\n",
       " 'WAP055': np.float64(3.662087415490918),\n",
       " 'WAP056': np.float64(3.5949021398847254),\n",
       " 'WAP057': np.float64(3.522549636078435),\n",
       " 'WAP058': np.float64(inf),\n",
       " 'WAP059': np.float64(2.8617109472790383),\n",
       " 'WAP060': np.float64(2.997139825928913),\n",
       " 'WAP061': np.float64(inf),\n",
       " 'WAP062': np.float64(inf),\n",
       " 'WAP063': np.float64(inf),\n",
       " 'WAP064': np.float64(2.516679876514598),\n",
       " 'WAP065': np.float64(inf),\n",
       " 'WAP066': np.float64(inf),\n",
       " 'WAP067': np.float64(3.4161052644450978),\n",
       " 'WAP068': np.float64(3.5022634603949996),\n",
       " 'WAP069': np.float64(3.4774661613716242),\n",
       " 'WAP070': np.float64(2.5079858142859233),\n",
       " 'WAP071': np.float64(3.8614499914023175),\n",
       " 'WAP072': np.float64(inf),\n",
       " 'WAP073': np.float64(3.3242159581686126),\n",
       " 'WAP074': np.float64(inf),\n",
       " 'WAP075': np.float64(3.654747150940281),\n",
       " 'WAP076': np.float64(3.402610337316344),\n",
       " 'WAP077': np.float64(inf),\n",
       " 'WAP078': np.float64(inf),\n",
       " 'WAP079': np.float64(3.274594349044137),\n",
       " 'WAP080': np.float64(2.746409651623404),\n",
       " 'WAP081': np.float64(inf),\n",
       " 'WAP082': np.float64(inf),\n",
       " 'WAP083': np.float64(inf),\n",
       " 'WAP084': np.float64(2.468520395754727),\n",
       " 'WAP085': np.float64(inf),\n",
       " 'WAP086': np.float64(3.007762520978662),\n",
       " 'WAP087': np.float64(inf),\n",
       " 'WAP088': np.float64(3.51541546874799),\n",
       " 'WAP089': np.float64(inf),\n",
       " 'WAP090': np.float64(inf),\n",
       " 'WAP091': np.float64(inf),\n",
       " 'WAP092': np.float64(3.474269620942286),\n",
       " 'WAP093': np.float64(3.543501412511853),\n",
       " 'WAP094': np.float64(3.5100181083848137),\n",
       " 'WAP095': np.float64(3.3939696785406324),\n",
       " 'WAP096': np.float64(1.9880043136150714),\n",
       " 'WAP097': np.float64(4.196998570248779),\n",
       " 'WAP098': np.float64(inf),\n",
       " 'WAP099': np.float64(3.167313255522416),\n",
       " 'WAP100': np.float64(inf),\n",
       " 'WAP101': np.float64(6.633941240608656),\n",
       " 'WAP102': np.float64(3.162158011689709),\n",
       " 'WAP103': np.float64(3.216815689945942),\n",
       " 'WAP104': np.float64(3.384746480315973),\n",
       " 'WAP105': np.float64(inf),\n",
       " 'WAP106': np.float64(inf),\n",
       " 'WAP107': np.float64(3.0606291407046555),\n",
       " 'WAP108': np.float64(2.9124680525278825),\n",
       " 'WAP109': np.float64(inf),\n",
       " 'WAP110': np.float64(3.6331618593475867),\n",
       " 'WAP111': np.float64(3.032230779639258),\n",
       " 'WAP112': np.float64(2.914482222280842),\n",
       " 'WAP113': np.float64(inf),\n",
       " 'WAP114': np.float64(3.86062304737708),\n",
       " 'WAP115': np.float64(3.779109040611584),\n",
       " 'WAP116': np.float64(3.168995395206741),\n",
       " 'WAP117': np.float64(inf),\n",
       " 'WAP118': np.float64(4.20533673367996),\n",
       " 'WAP119': np.float64(4.03257712403525),\n",
       " 'WAP120': np.float64(3.782067969970104),\n",
       " 'WAP121': np.float64(2.4619720632666784),\n",
       " 'WAP122': np.float64(inf),\n",
       " 'WAP123': np.float64(3.2408504983715454),\n",
       " 'WAP124': np.float64(5.921985499367116),\n",
       " 'WAP125': np.float64(inf),\n",
       " 'WAP126': np.float64(5.205637166886177),\n",
       " 'WAP127': np.float64(3.903295519870432),\n",
       " 'WAP128': np.float64(2.5894989272517934),\n",
       " 'WAP129': np.float64(inf),\n",
       " 'WAP130': np.float64(inf),\n",
       " 'WAP131': np.float64(inf),\n",
       " 'WAP132': np.float64(inf),\n",
       " 'WAP133': np.float64(3.0253429071679356),\n",
       " 'WAP134': np.float64(3.742809581940824),\n",
       " 'WAP135': np.float64(2.8304524696900697),\n",
       " 'WAP136': np.float64(4.415093938777514),\n",
       " 'WAP137': np.float64(inf),\n",
       " 'WAP138': np.float64(inf),\n",
       " 'WAP139': np.float64(inf),\n",
       " 'WAP140': np.float64(3.250844816721386),\n",
       " 'WAP141': np.float64(3.2164609410652227),\n",
       " 'WAP142': np.float64(3.8016201701039773),\n",
       " 'WAP143': np.float64(2.8107231524459473),\n",
       " 'WAP144': np.float64(inf),\n",
       " 'WAP145': np.float64(inf),\n",
       " 'WAP146': np.float64(inf),\n",
       " 'WAP147': np.float64(inf),\n",
       " 'WAP148': np.float64(inf),\n",
       " 'WAP149': np.float64(inf),\n",
       " 'WAP150': np.float64(inf),\n",
       " 'WAP151': np.float64(inf),\n",
       " 'WAP152': np.float64(3.4478654467458005),\n",
       " 'WAP153': np.float64(4.118202184762869),\n",
       " 'WAP154': np.float64(2.354378784813433),\n",
       " 'WAP155': np.float64(3.547816166777069),\n",
       " 'WAP156': np.float64(2.8465178664236332),\n",
       " 'WAP157': np.float64(3.89279319067244),\n",
       " 'WAP158': np.float64(3.511752714197045),\n",
       " 'WAP159': np.float64(3.436529292959449),\n",
       " 'WAP160': np.float64(3.4843537400090447),\n",
       " 'WAP161': np.float64(2.5781894641906917),\n",
       " 'WAP162': np.float64(inf),\n",
       " 'WAP163': np.float64(2.9574238217569184),\n",
       " 'WAP164': np.float64(3.6760539604651785),\n",
       " 'WAP165': np.float64(2.9046201029099192),\n",
       " 'WAP166': np.float64(inf),\n",
       " 'WAP167': np.float64(3.433032741362369),\n",
       " 'WAP168': np.float64(3.0881835812288885),\n",
       " 'WAP169': np.float64(inf),\n",
       " 'WAP170': np.float64(inf),\n",
       " 'WAP171': np.float64(3.1358822539163382),\n",
       " 'WAP172': np.float64(2.817619482818203),\n",
       " 'WAP173': np.float64(3.465413645747078),\n",
       " 'WAP174': np.float64(3.4132731759305046),\n",
       " 'WAP175': np.float64(3.13900700389438),\n",
       " 'WAP176': np.float64(2.786129935837205),\n",
       " 'WAP177': np.float64(4.873261470856502),\n",
       " 'WAP178': np.float64(4.233111603831728),\n",
       " 'WAP179': np.float64(4.110207353779108),\n",
       " 'WAP180': np.float64(3.268216891549335),\n",
       " 'WAP181': np.float64(3.6170680295482285),\n",
       " 'WAP182': np.float64(inf),\n",
       " 'WAP183': np.float64(inf),\n",
       " 'WAP184': np.float64(4.720643601804474),\n",
       " 'WAP185': np.float64(3.168739780201452),\n",
       " 'WAP186': np.float64(3.2656407823424614),\n",
       " 'WAP187': np.float64(3.7612885062131323),\n",
       " 'WAP188': np.float64(3.6093499766795993),\n",
       " 'WAP189': np.float64(2.981319647155384),\n",
       " 'WAP190': np.float64(2.799491500801974),\n",
       " 'WAP191': np.float64(3.892376265191077),\n",
       " 'WAP192': np.float64(inf),\n",
       " 'WAP193': np.float64(4.661183859343701),\n",
       " 'WAP194': np.float64(3.358775253024036),\n",
       " 'WAP195': np.float64(2.9945497485481622),\n",
       " 'WAP196': np.float64(3.5748018573107143),\n",
       " 'WAP197': np.float64(3.8258547843377584),\n",
       " 'WAP198': np.float64(3.7580925079756335),\n",
       " 'WAP199': np.float64(3.397898684837974),\n",
       " 'WAP200': np.float64(3.248901230987984),\n",
       " 'WAP201': np.float64(5.278498919080087),\n",
       " 'WAP202': np.float64(3.555983072711617),\n",
       " 'WAP203': np.float64(5.4591828477212765),\n",
       " 'WAP204': np.float64(inf),\n",
       " 'WAP205': np.float64(4.05945572470644),\n",
       " 'WAP206': np.float64(4.235529362937839),\n",
       " 'WAP207': np.float64(3.8007571244471396),\n",
       " 'WAP208': np.float64(3.2747224946727607),\n",
       " 'WAP209': np.float64(3.9552658978714805),\n",
       " 'WAP210': np.float64(3.312280038648329),\n",
       " 'WAP211': np.float64(2.9054145483986065),\n",
       " 'WAP212': np.float64(3.42283941592349),\n",
       " 'WAP213': np.float64(3.704301813362815),\n",
       " 'WAP214': np.float64(2.9012902396880316),\n",
       " 'WAP215': np.float64(3.497959392064768),\n",
       " 'WAP216': np.float64(3.6569886915814123),\n",
       " 'WAP217': np.float64(3.4843537400089133),\n",
       " 'WAP218': np.float64(2.9147336837399913),\n",
       " 'WAP219': np.float64(3.5736367042783463),\n",
       " 'WAP220': np.float64(3.4532711701476235),\n",
       " 'WAP221': np.float64(3.246234700910406),\n",
       " 'WAP222': np.float64(4.019818106948616),\n",
       " 'WAP223': np.float64(3.4621526544960615),\n",
       " 'WAP224': np.float64(2.7635440579983905),\n",
       " 'WAP225': np.float64(3.5190570530744747),\n",
       " 'WAP226': np.float64(3.5152309785734293),\n",
       " 'WAP227': np.float64(3.444613411359491),\n",
       " 'WAP228': np.float64(3.0007197898516607),\n",
       " 'WAP229': np.float64(2.856839919474871),\n",
       " 'WAP230': np.float64(2.7892165303562133),\n",
       " 'WAP231': np.float64(4.45119502883806),\n",
       " 'WAP232': np.float64(4.012510412814079),\n",
       " 'WAP233': np.float64(4.083945084566249),\n",
       " 'WAP234': np.float64(inf),\n",
       " 'WAP235': np.float64(inf),\n",
       " 'WAP236': np.float64(3.8088388510423554),\n",
       " 'WAP237': np.float64(3.2717021027193254),\n",
       " 'WAP238': np.float64(3.547092080642334),\n",
       " 'WAP239': np.float64(3.53458074675335),\n",
       " 'WAP240': np.float64(3.4446134113596307),\n",
       " 'WAP241': np.float64(3.610192787010398),\n",
       " 'WAP242': np.float64(3.465943178165842),\n",
       " 'WAP243': np.float64(3.496248527661126),\n",
       " 'WAP244': np.float64(3.4301087251565168),\n",
       " 'WAP245': np.float64(3.4494954389567134),\n",
       " 'WAP246': np.float64(3.472598776777599),\n",
       " 'WAP247': np.float64(3.4560421071832077),\n",
       " 'WAP248': np.float64(3.4604330173012703),\n",
       " 'WAP249': np.float64(inf),\n",
       " 'WAP250': np.float64(3.8050353369313914),\n",
       " 'WAP251': np.float64(3.9086725692272952),\n",
       " 'WAP252': np.float64(5.756636409133992),\n",
       " 'WAP253': np.float64(4.0768265423767405),\n",
       " 'WAP254': np.float64(3.3924276581889847),\n",
       " 'WAP255': np.float64(3.376999978480877),\n",
       " 'WAP256': np.float64(inf),\n",
       " 'WAP257': np.float64(3.357375073142894),\n",
       " 'WAP258': np.float64(inf),\n",
       " 'WAP259': np.float64(inf),\n",
       " 'WAP260': np.float64(5.000824912035703),\n",
       " 'WAP261': np.float64(3.7942317548279862),\n",
       " 'WAP262': np.float64(inf),\n",
       " 'WAP263': np.float64(3.847198300176918),\n",
       " 'WAP264': np.float64(3.9938448798720847),\n",
       " 'WAP265': np.float64(inf),\n",
       " 'WAP266': np.float64(4.176696139761195),\n",
       " 'WAP267': np.float64(5.759791226034507),\n",
       " 'WAP268': np.float64(3.0114020602607043),\n",
       " 'WAP269': np.float64(inf),\n",
       " 'WAP270': np.float64(3.595360004785953),\n",
       " 'WAP271': np.float64(4.472327288151973),\n",
       " 'WAP272': np.float64(2.868411397947498),\n",
       " 'WAP273': np.float64(3.9722354683966934),\n",
       " 'WAP274': np.float64(inf),\n",
       " 'WAP275': np.float64(4.262915898914763),\n",
       " 'WAP276': np.float64(inf),\n",
       " 'WAP277': np.float64(2.780432123002314),\n",
       " 'WAP278': np.float64(inf),\n",
       " 'WAP279': np.float64(inf),\n",
       " 'WAP280': np.float64(4.728422102622451),\n",
       " 'WAP281': np.float64(inf),\n",
       " 'WAP282': np.float64(inf),\n",
       " 'WAP283': np.float64(4.18715018702091),\n",
       " 'WAP284': np.float64(3.6869408753174784),\n",
       " 'WAP285': np.float64(4.482426494515264),\n",
       " 'WAP286': np.float64(inf),\n",
       " 'WAP287': np.float64(3.4631004158249494),\n",
       " 'WAP288': np.float64(4.537887617354391),\n",
       " 'WAP289': np.float64(5.149951072987105),\n",
       " 'WAP290': np.float64(5.450149609982884),\n",
       " 'WAP291': np.float64(4.312495554461726),\n",
       " 'WAP292': np.float64(inf),\n",
       " 'WAP293': np.float64(3.4285100037927263),\n",
       " 'WAP294': np.float64(3.539574318165349),\n",
       " 'WAP295': np.float64(4.334713676548157),\n",
       " 'WAP296': np.float64(3.583726213822196),\n",
       " 'WAP297': np.float64(3.1159775418771396),\n",
       " 'WAP298': np.float64(4.9907969228443765),\n",
       " 'WAP299': np.float64(4.6087619969055895),\n",
       " 'WAP300': np.float64(inf),\n",
       " 'WAP301': np.float64(3.42214055550731),\n",
       " 'WAP302': np.float64(3.8844835750329034),\n",
       " 'WAP303': np.float64(3.436529292959528),\n",
       " 'WAP304': np.float64(3.506557897320059),\n",
       " 'WAP305': np.float64(3.2393451283162693),\n",
       " 'WAP306': np.float64(5.128600652268904),\n",
       " 'WAP307': np.float64(3.395514080392159),\n",
       " 'WAP308': np.float64(5.243201614909046),\n",
       " 'WAP309': np.float64(3.25135452579363),\n",
       " 'WAP310': np.float64(3.3566058523831184),\n",
       " 'WAP311': np.float64(3.922055072121589),\n",
       " 'WAP312': np.float64(2.9909744462669385),\n",
       " 'WAP313': np.float64(3.1705511225201333),\n",
       " 'WAP314': np.float64(3.182220339783152),\n",
       " 'WAP315': np.float64(inf),\n",
       " 'WAP316': np.float64(inf),\n",
       " 'WAP317': np.float64(inf),\n",
       " 'WAP318': np.float64(3.3805418041594955),\n",
       " 'WAP319': np.float64(2.8380623263968894),\n",
       " 'WAP320': np.float64(4.05416805168234),\n",
       " 'WAP321': np.float64(inf),\n",
       " 'WAP322': np.float64(3.7504825810385607),\n",
       " 'WAP323': np.float64(2.81968019133648),\n",
       " 'WAP324': np.float64(3.642385568741998),\n",
       " 'WAP325': np.float64(4.979684516196832),\n",
       " 'WAP326': np.float64(inf),\n",
       " 'WAP327': np.float64(3.536193913207619),\n",
       " 'WAP328': np.float64(4.342704159983411),\n",
       " 'WAP329': np.float64(5.430272913260209),\n",
       " 'WAP330': np.float64(3.643568175545136),\n",
       " 'WAP331': np.float64(inf),\n",
       " 'WAP332': np.float64(4.087574317715721),\n",
       " 'WAP333': np.float64(3.444613411359415),\n",
       " 'WAP334': np.float64(inf),\n",
       " 'WAP335': np.float64(inf),\n",
       " 'WAP336': np.float64(3.6260838682457455),\n",
       " 'WAP337': np.float64(3.3107519389310593),\n",
       " 'WAP338': np.float64(3.004183145541252),\n",
       " 'WAP339': np.float64(3.428280548658332),\n",
       " 'WAP340': np.float64(4.367030303011916),\n",
       " 'WAP341': np.float64(4.7565191883368785),\n",
       " 'WAP342': np.float64(inf),\n",
       " 'WAP343': np.float64(3.3787627482602156),\n",
       " 'WAP344': np.float64(4.597034324491134),\n",
       " 'WAP345': np.float64(3.3676173717876674),\n",
       " 'WAP346': np.float64(3.7433551598669346),\n",
       " 'WAP347': np.float64(3.183031899932807),\n",
       " 'WAP348': np.float64(inf),\n",
       " 'WAP349': np.float64(3.5292662966897854),\n",
       " 'WAP350': np.float64(2.8652319836072766),\n",
       " 'WAP351': np.float64(2.5689201866320377),\n",
       " 'WAP352': np.float64(4.464050334086199),\n",
       " 'WAP353': np.float64(3.518721383513187),\n",
       " 'WAP354': np.float64(2.7594214377351074),\n",
       " 'WAP355': np.float64(3.761012360378323),\n",
       " 'WAP356': np.float64(3.4401306496424366),\n",
       " 'WAP357': np.float64(3.8912560208510842),\n",
       " 'WAP358': np.float64(inf),\n",
       " 'WAP359': np.float64(3.398014848132663),\n",
       " 'WAP360': np.float64(3.442991350987589),\n",
       " 'WAP361': np.float64(3.8487646510345317),\n",
       " 'WAP362': np.float64(inf),\n",
       " 'WAP363': np.float64(3.8775977363489345),\n",
       " 'WAP364': np.float64(3.359336777509986),\n",
       " 'WAP365': np.float64(3.591216885551488),\n",
       " 'WAP366': np.float64(4.224079266335202),\n",
       " 'WAP367': np.float64(3.8779319697336097),\n",
       " 'WAP368': np.float64(2.856188484387084),\n",
       " 'WAP369': np.float64(inf),\n",
       " 'WAP370': np.float64(3.2406410232980036),\n",
       " 'WAP371': np.float64(3.4019475506691133),\n",
       " 'WAP372': np.float64(4.1255587336873605),\n",
       " 'WAP373': np.float64(5.252091911104278),\n",
       " 'WAP374': np.float64(inf),\n",
       " 'WAP375': np.float64(inf),\n",
       " 'WAP376': np.float64(3.646936551635805),\n",
       " 'WAP377': np.float64(4.043494033524484),\n",
       " 'WAP378': np.float64(inf),\n",
       " 'WAP379': np.float64(inf),\n",
       " 'WAP380': np.float64(4.52194800903361),\n",
       " 'WAP381': np.float64(3.638010633683001),\n",
       " 'WAP382': np.float64(3.180431054112347),\n",
       " 'WAP383': np.float64(4.672924166162655),\n",
       " 'WAP384': np.float64(3.3840200545841017),\n",
       " 'WAP385': np.float64(2.7135665714884296),\n",
       " 'WAP386': np.float64(inf),\n",
       " 'WAP387': np.float64(3.108216371084598),\n",
       " 'WAP388': np.float64(3.601846370745729),\n",
       " 'WAP389': np.float64(inf),\n",
       " 'WAP390': np.float64(3.9851109765331696),\n",
       " 'WAP391': np.float64(4.084855519960874),\n",
       " 'WAP392': np.float64(5.099371511029587),\n",
       " 'WAP393': np.float64(3.025526901635067),\n",
       " 'WAP394': np.float64(2.8287366730596126),\n",
       " 'WAP395': np.float64(4.897130292516306),\n",
       " 'WAP396': np.float64(4.036770593651809),\n",
       " 'WAP397': np.float64(inf),\n",
       " 'WAP398': np.float64(inf),\n",
       " 'WAP399': np.float64(inf),\n",
       " 'WAP400': np.float64(3.4695703551082793),\n",
       " 'WAP401': np.float64(4.037400945187304),\n",
       " 'WAP402': np.float64(3.4791690379905216),\n",
       " 'WAP403': np.float64(4.048821282051051),\n",
       " 'WAP404': np.float64(3.330813894055617),\n",
       " 'WAP405': np.float64(inf),\n",
       " 'WAP406': np.float64(4.856618119836561),\n",
       " 'WAP407': np.float64(3.745121692753813),\n",
       " 'WAP408': np.float64(inf),\n",
       " 'WAP409': np.float64(inf),\n",
       " 'WAP410': np.float64(3.853097219391092),\n",
       " 'WAP411': np.float64(4.160672599273126),\n",
       " 'WAP412': np.float64(3.0726765690927067),\n",
       " 'WAP413': np.float64(3.0261060415336054),\n",
       " 'WAP414': np.float64(4.390909963083022),\n",
       " 'WAP415': np.float64(3.6494580400144363),\n",
       " 'WAP416': np.float64(3.5292662966898125),\n",
       " 'WAP417': np.float64(2.8296601843147338),\n",
       " 'WAP418': np.float64(inf),\n",
       " 'WAP419': np.float64(3.5543123286158433),\n",
       " 'WAP420': np.float64(3.256943753054842),\n",
       " 'WAP421': np.float64(4.092781030694259),\n",
       " 'WAP422': np.float64(3.832867626700788),\n",
       " 'WAP423': np.float64(3.606368690571812),\n",
       " 'WAP424': np.float64(inf),\n",
       " 'WAP425': np.float64(4.4021952052935385),\n",
       " 'WAP426': np.float64(inf),\n",
       " 'WAP427': np.float64(3.774043233619976),\n",
       " 'WAP428': np.float64(3.6146096643947243),\n",
       " 'WAP429': np.float64(3.380176356408404),\n",
       " 'WAP430': np.float64(3.2076865902078686),\n",
       " 'WAP431': np.float64(inf),\n",
       " 'WAP432': np.float64(2.905857020942472),\n",
       " 'WAP433': np.float64(3.4095220915481685),\n",
       " 'WAP434': np.float64(inf),\n",
       " 'WAP435': np.float64(4.180088397009834),\n",
       " 'WAP436': np.float64(4.1380830165519065),\n",
       " 'WAP437': np.float64(4.4733819236021235),\n",
       " 'WAP438': np.float64(3.2585111317255167),\n",
       " 'WAP439': np.float64(3.650925533009876),\n",
       " 'WAP440': np.float64(5.630485443007399),\n",
       " 'WAP441': np.float64(3.4429913509876617),\n",
       " 'WAP442': np.float64(3.539923591163787),\n",
       " 'WAP443': np.float64(2.8450038454091504),\n",
       " 'WAP444': np.float64(3.332619103879362),\n",
       " 'WAP445': np.float64(3.3741065350412796),\n",
       " 'WAP446': np.float64(3.2996551058209116),\n",
       " 'WAP447': np.float64(3.2971415834704736),\n",
       " 'WAP448': np.float64(3.4815643202545674),\n",
       " 'WAP449': np.float64(3.5786082052832273),\n",
       " 'WAP450': np.float64(3.9592634755197693),\n",
       " 'WAP451': np.float64(3.5615850879447786),\n",
       " 'WAP452': np.float64(3.1453302565860457),\n",
       " 'WAP453': np.float64(inf),\n",
       " 'WAP454': np.float64(3.752195003042975),\n",
       " 'WAP455': np.float64(3.008732838563725),\n",
       " 'WAP456': np.float64(3.329072077730891),\n",
       " 'WAP457': np.float64(2.986936718541689),\n",
       " 'WAP458': np.float64(3.390888012003335),\n",
       " 'WAP459': np.float64(inf),\n",
       " 'WAP460': np.float64(4.471856312638341),\n",
       " 'WAP461': np.float64(inf),\n",
       " 'WAP462': np.float64(4.572533756424032),\n",
       " 'WAP463': np.float64(4.999393243369992),\n",
       " 'WAP464': np.float64(3.3968330454645894),\n",
       " 'WAP465': np.float64(4.787508407786807),\n",
       " 'WAP466': np.float64(2.601946076850082),\n",
       " 'WAP467': np.float64(3.1396694558918155),\n",
       " 'WAP468': np.float64(inf),\n",
       " 'WAP469': np.float64(inf),\n",
       " 'WAP470': np.float64(3.3588653796139973),\n",
       " 'WAP471': np.float64(3.5336933333561387),\n",
       " 'WAP472': np.float64(inf),\n",
       " 'WAP473': np.float64(3.4240685715966905),\n",
       " 'WAP474': np.float64(inf),\n",
       " 'WAP475': np.float64(5.047265464577987),\n",
       " 'WAP476': np.float64(inf),\n",
       " 'WAP477': np.float64(3.5985258145968637),\n",
       " 'WAP478': np.float64(4.268013313775269),\n",
       " 'WAP479': np.float64(2.448060966705305),\n",
       " 'WAP480': np.float64(2.5551575327562275),\n",
       " 'WAP481': np.float64(inf),\n",
       " 'WAP482': np.float64(3.447865446745746),\n",
       " 'WAP483': np.float64(4.874337694760353),\n",
       " 'WAP484': np.float64(inf),\n",
       " 'WAP485': np.float64(3.393969678540628),\n",
       " 'WAP486': np.float64(2.7266103985124137),\n",
       " 'WAP487': np.float64(3.4626319168620796),\n",
       " 'WAP488': np.float64(3.3847530234357617),\n",
       " 'WAP489': np.float64(inf),\n",
       " 'WAP490': np.float64(3.446804521957085),\n",
       " 'WAP491': np.float64(3.38475302343585),\n",
       " 'WAP492': np.float64(4.428890556950556),\n",
       " 'WAP493': np.float64(4.769712599452572),\n",
       " 'WAP494': np.float64(3.0429876303727723),\n",
       " 'WAP495': np.float64(inf),\n",
       " 'WAP496': np.float64(2.6241825486646584),\n",
       " 'WAP497': np.float64(3.400161648788755),\n",
       " 'WAP498': np.float64(3.985075818934347),\n",
       " 'WAP499': np.float64(3.3954062569373478),\n",
       " 'WAP500': np.float64(3.274342526437728),\n",
       " 'WAP501': np.float64(inf),\n",
       " 'WAP502': np.float64(inf),\n",
       " 'WAP503': np.float64(2.565960121443929),\n",
       " 'WAP504': np.float64(3.8212381272545164),\n",
       " 'WAP505': np.float64(3.317833983888502),\n",
       " 'WAP506': np.float64(inf),\n",
       " 'WAP507': np.float64(3.518253127599358),\n",
       " 'WAP508': np.float64(3.6375685520437893),\n",
       " 'WAP509': np.float64(3.6619247579940506),\n",
       " 'WAP510': np.float64(3.2650514854717563),\n",
       " 'WAP511': np.float64(inf),\n",
       " 'WAP512': np.float64(inf),\n",
       " 'WAP513': np.float64(2.992560030282096),\n",
       " 'WAP514': np.float64(4.179183552050818),\n",
       " 'WAP515': np.float64(3.917806222140673),\n",
       " 'WAP516': np.float64(inf),\n",
       " 'WAP517': np.float64(inf),\n",
       " 'WAP518': np.float64(3.103966443868227),\n",
       " 'WAP519': np.float64(3.8126728405451895),\n",
       " 'WAP520': np.float64(3.5800018147310984),\n",
       " 'LONGITUDE': np.float64(0.07743231609938343),\n",
       " 'LATITUDE': np.float64(0.10354776503686423),\n",
       " 'SPACEID': np.float64(0.10417482675758623),\n",
       " 'RELATIVEPOSITION': np.float64(9.40968121156358),\n",
       " 'USERID': np.float64(2.806146525644485),\n",
       " 'PHONEID': np.float64(2.1226497900052754),\n",
       " 'TIMESTAMP': np.float64(-6.102775047675099e-17)}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "kl_divergences = {}\n",
    "\n",
    "# Calculate KL divergence for each column\n",
    "for column in train_data.columns:\n",
    "    if column in [\"FLOOR\", \"BUILDINGID\"]:\n",
    "        continue\n",
    "    kl_divergences[column] = entropy(\n",
    "        np.histogram(train_data1[column], bins=100, range=(train_data1[column].min(), train_data1[column].max()), density=True)[0],\n",
    "        np.histogram(data_drifted[column], bins=100, range=(data_drifted[column].min(), data_drifted[column].max()), density=True)[0],\n",
    "    )\n",
    "\n",
    "with mlflow.start_run(run_name=\"DataDrift\"):\n",
    "\n",
    "    # Log datasets as artifacts\n",
    "    train_data2.to_csv(\"data/ujiindoorloc/trainingData.csv\", index=False)\n",
    "    data_drifted.to_csv(\"data/ujiindoorloc/data_drifted.csv\", index=False)\n",
    "    mlflow.log_artifact(\"data/ujiindoorloc/trainingData.csv\")\n",
    "    mlflow.log_artifact(\"data/ujiindoorloc/data_drifted.csv\")\n",
    "\n",
    "    # Log KL divergence\n",
    "\n",
    "    mlflow.log_param(\"kl_divergences\", kl_divergences)\n",
    "\n",
    "kl_divergences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
